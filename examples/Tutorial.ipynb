{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to pyNS \n",
    "pyNS is a Python library to programmatically access the Neuroscout API. pyNS let's you query the API and create analyses, without having to mess around with buildling any JSON requests yourself.\n",
    "\n",
    "In this tutorial, I'll demonstrate how to query the API to create your own analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyns import Neuroscout\n",
    "api = Neuroscout('user@university.edu', 'yourpassword')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Neuroscout` object will be your main entry point to the API. You can instantiate this object without any credentials to access public API routes, or preferably with your Neuroscout credentials to be able to create and save your analyses. The `Neuroscout` object has links to each main API route, and each of these links implements the standard HTTP verbs that are suppoted by each route, such as `datasets`, `runs`, `predictors`, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying datasets and runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'description': {'Authors': ['Zadbood, A., Chen, J., Leong, Y.C., Norman, K.A., & Hasson, U.'],\n",
       "   'BIDSVersion': '1.0.2',\n",
       "   'Funding': 'National Institutes of Health (1R01MH112357-01 and 1R01MH112566-01)',\n",
       "   'Name': 'Sherlock_Merlin',\n",
       "   'ReferencesAndLinks': ['https://academic.oup.com/cercor/article/doi/10.1093/cercor/bhx202/4080827/How-We-Transmit-Memories-to-Other-Brains']},\n",
       "  'id': 5,\n",
       "  'mimetypes': ['audio/x-wav', 'image/png', 'text/plain', 'video/mp4'],\n",
       "  'name': 'SherlockMerlin',\n",
       "  'runs': [126,\n",
       "   127,\n",
       "   128,\n",
       "   129,\n",
       "   117,\n",
       "   118,\n",
       "   119,\n",
       "   120,\n",
       "   121,\n",
       "   122,\n",
       "   124,\n",
       "   125,\n",
       "   130,\n",
       "   131,\n",
       "   132,\n",
       "   133,\n",
       "   134],\n",
       "  'summary': 'Participants watched Sherlock movie and listened to the audio recording of Merlin movie.',\n",
       "  'tasks': [{'id': 4, 'name': 'MerlinMovie'}]},\n",
       " {'description': {'Acknowledgments': 'We thank Jason Gors, Kelsey G. Wheeler J. Swaroop Guntupalli, Matteo Visconti di Oleggio Castello, M. Ida Gobbini, Terry Sacket, and the rest of the DBIC (Dartmouth Brain Imaging Center) personnel for assistance in data collection/curation.',\n",
       "   'Authors': ['Samuel A. Nastase',\n",
       "    'Yaroslav O. Halchenko',\n",
       "    'Andrew C. Connolly',\n",
       "    'James V. Haxby'],\n",
       "   'BIDSVersion': '1.0.1',\n",
       "   'Funding': ['5R01MH075706', 'F32MH085433-01A1', 'NSF1129764'],\n",
       "   'HowToAcknowledge': 'If you find this data set useful, please cite the following paper: Nastase, S. A., Connolly, A. C., Oosterhof, N. N., Halchenko, Y. O., Guntupalli, J. S., di Oleggio Castello, M. V., Gors, J., Gobbini, M. I., & Haxby, J. V. (2017). Attention selectively reshapes the geometry of distributed semantic representation. Cerebral Cortex.',\n",
       "   'License': 'PDDL',\n",
       "   'Name': 'Neural responses to naturalistic clips of animals'},\n",
       "  'id': 9,\n",
       "  'mimetypes': ['audio/x-wav', 'image/png', 'text/plain', 'video/x-matroska'],\n",
       "  'name': 'Life',\n",
       "  'runs': [241,\n",
       "   242,\n",
       "   243,\n",
       "   244,\n",
       "   245,\n",
       "   246,\n",
       "   247,\n",
       "   248,\n",
       "   249,\n",
       "   250,\n",
       "   251,\n",
       "   252,\n",
       "   253,\n",
       "   254,\n",
       "   255,\n",
       "   256,\n",
       "   257,\n",
       "   258,\n",
       "   259,\n",
       "   260,\n",
       "   261,\n",
       "   262,\n",
       "   263,\n",
       "   264,\n",
       "   265,\n",
       "   266,\n",
       "   267,\n",
       "   268,\n",
       "   269,\n",
       "   270,\n",
       "   271,\n",
       "   272,\n",
       "   273,\n",
       "   274,\n",
       "   275,\n",
       "   276,\n",
       "   277,\n",
       "   278,\n",
       "   279,\n",
       "   280,\n",
       "   281,\n",
       "   282,\n",
       "   283,\n",
       "   284,\n",
       "   285,\n",
       "   286,\n",
       "   287,\n",
       "   288,\n",
       "   289,\n",
       "   290,\n",
       "   291,\n",
       "   292,\n",
       "   293,\n",
       "   294,\n",
       "   295,\n",
       "   296,\n",
       "   297,\n",
       "   298,\n",
       "   299,\n",
       "   300,\n",
       "   301,\n",
       "   302,\n",
       "   303,\n",
       "   304,\n",
       "   305,\n",
       "   306,\n",
       "   307,\n",
       "   308,\n",
       "   309,\n",
       "   235,\n",
       "   236,\n",
       "   237,\n",
       "   238,\n",
       "   239,\n",
       "   240,\n",
       "   310],\n",
       "  'summary': 'Four segments of the Life nature documentary narrated by David Attenborough',\n",
       "  'tasks': [{'id': 8, 'name': 'life'}]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.datasets.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This request returns a list of two datasets, with information about the dataset, as well as the run IDs associated with this dataset. Let's focus on the first dataset, `Sherlock_Merlin`\n",
    "\n",
    "If we want more information on the specific runs within this dataset, we can query the `runs` route, using the dataset_id associated with `Sherlock_Merlin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1543.5,\n",
       "  'id': 126,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '28',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1540.5,\n",
       "  'id': 127,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '29',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1543.5,\n",
       "  'id': 128,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '30',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1539.0,\n",
       "  'id': 129,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '31',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1545.0,\n",
       "  'id': 117,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '19',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1546.5,\n",
       "  'id': 118,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '20',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1540.5,\n",
       "  'id': 119,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '21',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1539.0,\n",
       "  'id': 120,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '22',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1539.0,\n",
       "  'id': 121,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '23',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1540.5,\n",
       "  'id': 122,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '24',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1543.5,\n",
       "  'id': 124,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '26',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1542.0,\n",
       "  'id': 125,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '27',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1545.0,\n",
       "  'id': 130,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '32',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1561.5,\n",
       "  'id': 131,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '33',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1542.0,\n",
       "  'id': 132,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '34',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1542.0,\n",
       "  'id': 133,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '35',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}},\n",
       " {'acquisition': None,\n",
       "  'dataset_id': 5,\n",
       "  'duration': 1545.0,\n",
       "  'id': 134,\n",
       "  'number': None,\n",
       "  'session': None,\n",
       "  'subject': '36',\n",
       "  'task': {'id': 4, 'name': 'MerlinMovie'}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = api.datasets.get()[0]\n",
    "api.runs.get(dataset_id=dataset['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. In the analysis I'm buidling, I only want to focus on subjects '28' and '29', so lets extract those IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[126, 127]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ids = [r['id'] for r in api.runs.get(dataset_id=dataset['id']) if r['subject'] in ['28', '29']]\n",
    "run_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the predictors associated with these runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'description': 'Face detection confidence',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 19:43:02.103809',\n",
       "   'description': 'Face detection confidence',\n",
       "   'extractor_name': 'GoogleVisionAPIFaceExtractor',\n",
       "   'id': 220,\n",
       "   'modality': None},\n",
       "  'id': 354,\n",
       "  'max': 0.999985,\n",
       "  'mean': 0.8007437250667854,\n",
       "  'min': 0.5051182,\n",
       "  'name': 'face_detectionConfidence',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.17035985190329545},\n",
       " {'description': 'Face landmarking confidence',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 19:43:02.113270',\n",
       "   'description': 'Face landmarking confidence',\n",
       "   'extractor_name': 'GoogleVisionAPIFaceExtractor',\n",
       "   'id': 221,\n",
       "   'modality': None},\n",
       "  'id': 355,\n",
       "  'max': 0.8566273,\n",
       "  'mean': 0.4601388381104185,\n",
       "  'min': 0.10028671,\n",
       "  'name': 'face_landmarkingConfidence',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.18337511525219882},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 313,\n",
       "  'max': 0.2952060472,\n",
       "  'mean': 0.024379558385633434,\n",
       "  'min': 0.0,\n",
       "  'name': 'tCompCor04',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.019430171697458996},\n",
       " {'description': 'Variance of color channels',\n",
       "  'extracted_feature': {'created_at': '2018-04-18 23:55:42.506123',\n",
       "   'description': 'Variance of color channels',\n",
       "   'extractor_name': 'VibranceExtractor',\n",
       "   'id': 216,\n",
       "   'modality': None},\n",
       "  'id': 352,\n",
       "  'max': 2978.7402555941358,\n",
       "  'mean': 308.5342049309327,\n",
       "  'min': 1.0717525077160497,\n",
       "  'name': 'vibrance',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 330.71770773742116},\n",
       " {'description': 'Degree of blur/sharpness of the image',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 19:31:16.237414',\n",
       "   'description': 'Degree of blur/sharpness of the image',\n",
       "   'extractor_name': 'SharpnessExtractor',\n",
       "   'id': 219,\n",
       "   'modality': None},\n",
       "  'id': 353,\n",
       "  'max': 1.0,\n",
       "  'mean': 0.7320019685549253,\n",
       "  'min': 0.011764705882352941,\n",
       "  'name': 'sharpness',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.20987255016110185},\n",
       " {'description': 'Number of detected faces in scene',\n",
       "  'extracted_feature': {'created_at': '2018-05-02 22:47:50.952483',\n",
       "   'description': 'Number of detected faces in scene',\n",
       "   'extractor_name': 'GoogleVisionAPIFaceExtractor',\n",
       "   'id': 1356,\n",
       "   'modality': None},\n",
       "  'id': 763,\n",
       "  'max': 7.0,\n",
       "  'mean': 1.3546441495778045,\n",
       "  'min': 1.0,\n",
       "  'name': 'num_faces',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.8548291855376311},\n",
       " {'description': 'RGB Channel',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 17:33:16.910723',\n",
       "   'description': 'RGB Channel',\n",
       "   'extractor_name': 'GoogleVisionAPIPropertyExtractor',\n",
       "   'id': 13328,\n",
       "   'modality': None},\n",
       "  'id': 12726,\n",
       "  'max': 9.0,\n",
       "  'mean': 3.9610303830911495,\n",
       "  'min': 1.0,\n",
       "  'name': 'num_colors_0.07',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 1.236496608759762},\n",
       " {'description': 'Average luminosity of the pixels',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 20:47:59.365114',\n",
       "   'description': 'Average luminosity of the pixels',\n",
       "   'extractor_name': 'BrightnessExtractor',\n",
       "   'id': 13630,\n",
       "   'modality': None},\n",
       "  'id': 12728,\n",
       "  'max': 0.8665559810729848,\n",
       "  'mean': 0.3113551746764224,\n",
       "  'min': 0.008875340413943356,\n",
       "  'name': 'brightness',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.15173867959322807},\n",
       " {'description': 'Lexical frequency of words in corpus of 51 million words (log)',\n",
       "  'extracted_feature': {'created_at': '2018-05-29 23:06:26.074587',\n",
       "   'description': 'Lexical frequency of words in corpus of 51 million words (log)',\n",
       "   'extractor_name': 'PredefinedDictionaryExtractor',\n",
       "   'id': 84270,\n",
       "   'modality': None},\n",
       "  'id': 12914,\n",
       "  'max': 6.329339698310973,\n",
       "  'mean': 4.898777598394423,\n",
       "  'min': 0.4771212547196624,\n",
       "  'name': 'subtlexusfrequency_Lg10WF',\n",
       "  'num_na': 4862,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 1.080081749286979},\n",
       " {'description': 'Root mean square (RMS) energy from audio',\n",
       "  'extracted_feature': {'created_at': '2018-05-15 22:57:04.734631',\n",
       "   'description': 'Root mean square (RMS) energy from audio',\n",
       "   'extractor_name': 'RMSEExtractor',\n",
       "   'id': 78102,\n",
       "   'modality': None},\n",
       "  'id': 12898,\n",
       "  'max': 0.2920644911107239,\n",
       "  'mean': 0.06316106919404939,\n",
       "  'min': 0.0011371257785887992,\n",
       "  'name': 'rmse',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.044979684130666525},\n",
       " {'description': 'Clarifai image recognition label: abstract',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:08.854983',\n",
       "   'description': 'Clarifai image recognition label: abstract',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 350,\n",
       "   'modality': None},\n",
       "  'id': 356,\n",
       "  'max': 0.99688745,\n",
       "  'mean': 0.15554192170703435,\n",
       "  'min': 2.2032877e-05,\n",
       "  'name': 'abstract',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.24732606271826188},\n",
       " {'description': 'Clarifai image recognition label: action',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:08.868058',\n",
       "   'description': 'Clarifai image recognition label: action',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 351,\n",
       "   'modality': None},\n",
       "  'id': 357,\n",
       "  'max': 0.974104,\n",
       "  'mean': 0.27479466830845445,\n",
       "  'min': 0.004770173,\n",
       "  'name': 'action',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.22011018958635314},\n",
       " {'description': 'Clarifai image recognition label: adult',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:08.880426',\n",
       "   'description': 'Clarifai image recognition label: adult',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 352,\n",
       "   'modality': None},\n",
       "  'id': 358,\n",
       "  'max': 0.99761784,\n",
       "  'mean': 0.9043248602483488,\n",
       "  'min': 0.015903447,\n",
       "  'name': 'adult',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.20552340966093796},\n",
       " {'description': 'Clarifai image recognition label: alphabet',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:08.899959',\n",
       "   'description': 'Clarifai image recognition label: alphabet',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 353,\n",
       "   'modality': None},\n",
       "  'id': 359,\n",
       "  'max': 0.54062307,\n",
       "  'mean': 0.008549910445350067,\n",
       "  'min': 2.1158143e-05,\n",
       "  'name': 'alphabet',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.03748119667857629},\n",
       " {'description': 'Clarifai image recognition label: animal',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:08.913703',\n",
       "   'description': 'Clarifai image recognition label: animal',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 354,\n",
       "   'modality': None},\n",
       "  'id': 360,\n",
       "  'max': 0.96881485,\n",
       "  'mean': 0.06875310096852708,\n",
       "  'min': 0.0002919975,\n",
       "  'name': 'animal',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.12799666039984195},\n",
       " {'description': 'Clarifai image recognition label: architecture',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:08.927696',\n",
       "   'description': 'Clarifai image recognition label: architecture',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 355,\n",
       "   'modality': None},\n",
       "  'id': 361,\n",
       "  'max': 0.99269056,\n",
       "  'mean': 0.2604889328402906,\n",
       "  'min': 0.0028422012,\n",
       "  'name': 'architecture',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2821519664650611},\n",
       " {'description': 'Clarifai image recognition label: art',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:08.940255',\n",
       "   'description': 'Clarifai image recognition label: art',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 356,\n",
       "   'modality': None},\n",
       "  'id': 362,\n",
       "  'max': 0.9913738,\n",
       "  'mean': 0.4759221311968296,\n",
       "  'min': 0.03696377,\n",
       "  'name': 'art',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.22631753618882},\n",
       " {'description': 'Clarifai image recognition label: blur',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:08.949775',\n",
       "   'description': 'Clarifai image recognition label: blur',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 357,\n",
       "   'modality': None},\n",
       "  'id': 363,\n",
       "  'max': 0.9971636,\n",
       "  'mean': 0.37303364401116246,\n",
       "  'min': 0.0012133555,\n",
       "  'name': 'blur',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2655433015238662},\n",
       " {'description': 'Clarifai image recognition label: building',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:08.959809',\n",
       "   'description': 'Clarifai image recognition label: building',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 358,\n",
       "   'modality': None},\n",
       "  'id': 364,\n",
       "  'max': 0.97949636,\n",
       "  'mean': 0.3669693198624835,\n",
       "  'min': 0.005998519,\n",
       "  'name': 'building',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.25328036110938007},\n",
       " {'description': 'Clarifai image recognition label: business',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:08.970340',\n",
       "   'description': 'Clarifai image recognition label: business',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 359,\n",
       "   'modality': None},\n",
       "  'id': 365,\n",
       "  'max': 0.97185934,\n",
       "  'mean': 0.4385142872985469,\n",
       "  'min': 0.005312076,\n",
       "  'name': 'business',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.21156155047183012},\n",
       " {'description': 'Clarifai image recognition label: car',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:08.979734',\n",
       "   'description': 'Clarifai image recognition label: car',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 360,\n",
       "   'modality': None},\n",
       "  'id': 366,\n",
       "  'max': 0.7372871,\n",
       "  'mean': 0.10568331056730515,\n",
       "  'min': 0.0024719937,\n",
       "  'name': 'car',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.10770498372390948},\n",
       " {'description': 'Clarifai image recognition label: child',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:08.989905',\n",
       "   'description': 'Clarifai image recognition label: child',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 361,\n",
       "   'modality': None},\n",
       "  'id': 367,\n",
       "  'max': 0.9917778,\n",
       "  'mean': 0.5725336831723911,\n",
       "  'min': 0.010779222,\n",
       "  'name': 'child',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.23959122275439046},\n",
       " {'description': 'Clarifai image recognition label: city',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.002227',\n",
       "   'description': 'Clarifai image recognition label: city',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 362,\n",
       "   'modality': None},\n",
       "  'id': 368,\n",
       "  'max': 0.98643243,\n",
       "  'mean': 0.4950483859669749,\n",
       "  'min': 0.00963833,\n",
       "  'name': 'city',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2388928844138726},\n",
       " {'description': 'Clarifai image recognition label: color',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.012763',\n",
       "   'description': 'Clarifai image recognition label: color',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 363,\n",
       "   'modality': None},\n",
       "  'id': 369,\n",
       "  'max': 0.9665942,\n",
       "  'mean': 0.3933188736677675,\n",
       "  'min': 0.0037863257,\n",
       "  'name': 'color',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.21664073941750656},\n",
       " {'description': 'Clarifai image recognition label: competition',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.022804',\n",
       "   'description': 'Clarifai image recognition label: competition',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 364,\n",
       "   'modality': None},\n",
       "  'id': 370,\n",
       "  'max': 0.9540568,\n",
       "  'mean': 0.3222527139501321,\n",
       "  'min': 0.0039553,\n",
       "  'name': 'competition',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2142743203652174},\n",
       " {'description': 'Clarifai image recognition label: creativity',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.035016',\n",
       "   'description': 'Clarifai image recognition label: creativity',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 365,\n",
       "   'modality': None},\n",
       "  'id': 371,\n",
       "  'max': 0.8288574,\n",
       "  'mean': 0.14505848431809776,\n",
       "  'min': 0.0009875704,\n",
       "  'name': 'creativity',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.1238700170647577},\n",
       " {'description': 'Clarifai image recognition label: dark',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.046459',\n",
       "   'description': 'Clarifai image recognition label: dark',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 366,\n",
       "   'modality': None},\n",
       "  'id': 372,\n",
       "  'max': 0.99091345,\n",
       "  'mean': 0.4857909344258256,\n",
       "  'min': 0.0020180715,\n",
       "  'name': 'dark',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.28933827607566154},\n",
       " {'description': 'Clarifai image recognition label: daylight',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.058316',\n",
       "   'description': 'Clarifai image recognition label: daylight',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 367,\n",
       "   'modality': None},\n",
       "  'id': 373,\n",
       "  'max': 0.96143895,\n",
       "  'mean': 0.5548267020805813,\n",
       "  'min': 0.0069630845,\n",
       "  'name': 'daylight',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2238503433537499},\n",
       " {'description': 'Clarifai image recognition label: design',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.071518',\n",
       "   'description': 'Clarifai image recognition label: design',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 368,\n",
       "   'modality': None},\n",
       "  'id': 374,\n",
       "  'max': 0.9654349,\n",
       "  'mean': 0.2242517092334214,\n",
       "  'min': 0.004743034,\n",
       "  'name': 'design',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.23337505038303485},\n",
       " {'description': 'Clarifai image recognition label: desktop',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.085416',\n",
       "   'description': 'Clarifai image recognition label: desktop',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 369,\n",
       "   'modality': None},\n",
       "  'id': 375,\n",
       "  'max': 0.9940059,\n",
       "  'mean': 0.39308378586770143,\n",
       "  'min': 0.0026558312,\n",
       "  'name': 'desktop',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2728741026429679},\n",
       " {'description': 'Clarifai image recognition label: empty',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.105457',\n",
       "   'description': 'Clarifai image recognition label: empty',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 370,\n",
       "   'modality': None},\n",
       "  'id': 376,\n",
       "  'max': 0.9616888,\n",
       "  'mean': 0.09376853195708058,\n",
       "  'min': 6.281269e-05,\n",
       "  'name': 'empty',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.16144858845313795},\n",
       " {'description': 'Clarifai image recognition label: equipment',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.119164',\n",
       "   'description': 'Clarifai image recognition label: equipment',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 371,\n",
       "   'modality': None},\n",
       "  'id': 377,\n",
       "  'max': 0.84040534,\n",
       "  'mean': 0.11428898542476883,\n",
       "  'min': 0.003454905,\n",
       "  'name': 'equipment',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.14103689221591947},\n",
       " {'description': 'Clarifai image recognition label: face',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.132547',\n",
       "   'description': 'Clarifai image recognition label: face',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 372,\n",
       "   'modality': None},\n",
       "  'id': 378,\n",
       "  'max': 0.9914359,\n",
       "  'mean': 0.3744649701088507,\n",
       "  'min': 0.0021189312,\n",
       "  'name': 'face',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2896820640403719},\n",
       " {'description': 'Clarifai image recognition label: family',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.145360',\n",
       "   'description': 'Clarifai image recognition label: family',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 373,\n",
       "   'modality': None},\n",
       "  'id': 379,\n",
       "  'max': 0.9518822,\n",
       "  'mean': 0.5427801710541612,\n",
       "  'min': 0.03801243,\n",
       "  'name': 'family',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.1894584933423156},\n",
       " {'description': 'Clarifai image recognition label: fashion',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.159889',\n",
       "   'description': 'Clarifai image recognition label: fashion',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 374,\n",
       "   'modality': None},\n",
       "  'id': 380,\n",
       "  'max': 0.9734836,\n",
       "  'mean': 0.39429629776981506,\n",
       "  'min': 0.0037068604,\n",
       "  'name': 'fashion',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2391381421616139},\n",
       " {'description': 'Clarifai image recognition label: furniture',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.170886',\n",
       "   'description': 'Clarifai image recognition label: furniture',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 375,\n",
       "   'modality': None},\n",
       "  'id': 381,\n",
       "  'max': 0.99852103,\n",
       "  'mean': 0.4386952524047556,\n",
       "  'min': 0.002509861,\n",
       "  'name': 'furniture',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.28534938119434633},\n",
       " {'description': 'Clarifai image recognition label: girl',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.213426',\n",
       "   'description': 'Clarifai image recognition label: girl',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 376,\n",
       "   'modality': None},\n",
       "  'id': 382,\n",
       "  'max': 0.9889494,\n",
       "  'mean': 0.4713911961867239,\n",
       "  'min': 0.0018398499,\n",
       "  'name': 'girl',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.26941748218885264},\n",
       " {'description': 'Clarifai image recognition label: hand',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.230284',\n",
       "   'description': 'Clarifai image recognition label: hand',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 377,\n",
       "   'modality': None},\n",
       "  'id': 383,\n",
       "  'max': 0.9368834,\n",
       "  'mean': 0.17279400554504623,\n",
       "  'min': 0.0019523068,\n",
       "  'name': 'hand',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.16043692101305357},\n",
       " {'description': 'Clarifai image recognition label: home',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.244442',\n",
       "   'description': 'Clarifai image recognition label: home',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 378,\n",
       "   'modality': None},\n",
       "  'id': 384,\n",
       "  'max': 0.9829165,\n",
       "  'mean': 0.4148362006190885,\n",
       "  'min': 0.0009176738,\n",
       "  'name': 'home',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.24322268252510681},\n",
       " {'description': 'Clarifai image recognition label: horizontal',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.260284',\n",
       "   'description': 'Clarifai image recognition label: horizontal',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 379,\n",
       "   'modality': None},\n",
       "  'id': 385,\n",
       "  'max': 0.97805524,\n",
       "  'mean': 0.28092282455627476,\n",
       "  'min': 0.0073185842,\n",
       "  'name': 'horizontal',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2115799179974651},\n",
       " {'description': 'Clarifai image recognition label: illustration',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.274675',\n",
       "   'description': 'Clarifai image recognition label: illustration',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 380,\n",
       "   'modality': None},\n",
       "  'id': 386,\n",
       "  'max': 0.9843128,\n",
       "  'mean': 0.11100245919643328,\n",
       "  'min': 0.0020296923,\n",
       "  'name': 'illustration',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.18945828169773096},\n",
       " {'description': 'Clarifai image recognition label: image',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.289285',\n",
       "   'description': 'Clarifai image recognition label: image',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 381,\n",
       "   'modality': None},\n",
       "  'id': 387,\n",
       "  'max': 0.93072534,\n",
       "  'mean': 0.21692330821136063,\n",
       "  'min': 0.008588864,\n",
       "  'name': 'image',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.17959555177137587},\n",
       " {'description': 'Clarifai image recognition label: indoors',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.302153',\n",
       "   'description': 'Clarifai image recognition label: indoors',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 382,\n",
       "   'modality': None},\n",
       "  'id': 388,\n",
       "  'max': 0.99504393,\n",
       "  'mean': 0.7198360604872523,\n",
       "  'min': 0.0022708587,\n",
       "  'name': 'indoors',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.26289165793328323},\n",
       " {'description': 'Clarifai image recognition label: landscape',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.317144',\n",
       "   'description': 'Clarifai image recognition label: landscape',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 383,\n",
       "   'modality': None},\n",
       "  'id': 389,\n",
       "  'max': 0.99106747,\n",
       "  'mean': 0.3381179056400264,\n",
       "  'min': 0.008518569,\n",
       "  'name': 'landscape',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.23148377241397594},\n",
       " {'description': 'Clarifai image recognition label: light',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.330260',\n",
       "   'description': 'Clarifai image recognition label: light',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 384,\n",
       "   'modality': None},\n",
       "  'id': 390,\n",
       "  'max': 0.98461014,\n",
       "  'mean': 0.6624670268107662,\n",
       "  'min': 0.007070305,\n",
       "  'name': 'light',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2359164657601822},\n",
       " {'description': 'Clarifai image recognition label: man',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.342992',\n",
       "   'description': 'Clarifai image recognition label: man',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 385,\n",
       "   'modality': None},\n",
       "  'id': 391,\n",
       "  'max': 0.99601245,\n",
       "  'mean': 0.8509975768044914,\n",
       "  'min': 0.018852836,\n",
       "  'name': 'man',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2050623924500372},\n",
       " {'description': 'Transitions between scene cuts in video',\n",
       "  'extracted_feature': {'created_at': '2018-05-24 20:39:25.962612',\n",
       "   'description': 'Transitions between scene cuts in video',\n",
       "   'extractor_name': 'GoogleVideoAPIShotDetectionExtractor',\n",
       "   'id': 84267,\n",
       "   'modality': None},\n",
       "  'id': 12911,\n",
       "  'max': 1.0,\n",
       "  'mean': 1.0,\n",
       "  'min': 1.0,\n",
       "  'name': 'shot_change',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.0},\n",
       " {'description': 'Clarifai image recognition label: military',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.356756',\n",
       "   'description': 'Clarifai image recognition label: military',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 386,\n",
       "   'modality': None},\n",
       "  'id': 392,\n",
       "  'max': 0.9730041,\n",
       "  'mean': 0.3737856052704095,\n",
       "  'min': 0.0049689654,\n",
       "  'name': 'military',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.24305375371515595},\n",
       " {'description': 'Clarifai image recognition label: music',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.371288',\n",
       "   'description': 'Clarifai image recognition label: music',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 387,\n",
       "   'modality': None},\n",
       "  'id': 393,\n",
       "  'max': 0.9866615,\n",
       "  'mean': 0.6295251646064729,\n",
       "  'min': 0.00624993,\n",
       "  'name': 'music',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.23714769378760323},\n",
       " {'description': 'Clarifai image recognition label: nature',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.384129',\n",
       "   'description': 'Clarifai image recognition label: nature',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 388,\n",
       "   'modality': None},\n",
       "  'id': 394,\n",
       "  'max': 0.98590136,\n",
       "  'mean': 0.22559759755406208,\n",
       "  'min': 0.00038949196,\n",
       "  'name': 'nature',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2699331413266568},\n",
       " {'description': 'Clarifai image recognition label: old',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.398178',\n",
       "   'description': 'Clarifai image recognition label: old',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 389,\n",
       "   'modality': None},\n",
       "  'id': 395,\n",
       "  'max': 0.97941196,\n",
       "  'mean': 0.4116194745492074,\n",
       "  'min': 0.011457156,\n",
       "  'name': 'old',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.24606693214017558},\n",
       " {'description': 'Clarifai image recognition label: one',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.412410',\n",
       "   'description': 'Clarifai image recognition label: one',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 390,\n",
       "   'modality': None},\n",
       "  'id': 396,\n",
       "  'max': 0.99852204,\n",
       "  'mean': 0.8638443094821664,\n",
       "  'min': 0.022778546,\n",
       "  'name': 'one',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.22096271219665914},\n",
       " {'description': 'Clarifai image recognition label: outdoors',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.424933',\n",
       "   'description': 'Clarifai image recognition label: outdoors',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 391,\n",
       "   'modality': None},\n",
       "  'id': 397,\n",
       "  'max': 0.98590326,\n",
       "  'mean': 0.5729504531770145,\n",
       "  'min': 0.06601161,\n",
       "  'name': 'outdoors',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.24178132598719948},\n",
       " {'description': 'Clarifai image recognition label: pattern',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.437167',\n",
       "   'description': 'Clarifai image recognition label: pattern',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 392,\n",
       "   'modality': None},\n",
       "  'id': 398,\n",
       "  'max': 0.9765187,\n",
       "  'mean': 0.16407191636770146,\n",
       "  'min': 0.0025416468,\n",
       "  'name': 'pattern',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.19969228313785006},\n",
       " {'description': 'Clarifai image recognition label: people',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.450749',\n",
       "   'description': 'Clarifai image recognition label: people',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 393,\n",
       "   'modality': None},\n",
       "  'id': 399,\n",
       "  'max': 0.9993312,\n",
       "  'mean': 0.9476396532166447,\n",
       "  'min': 0.10442514,\n",
       "  'name': 'people',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.14331985604317254},\n",
       " {'description': 'Clarifai image recognition label: portrait',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.463243',\n",
       "   'description': 'Clarifai image recognition label: portrait',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 394,\n",
       "   'modality': None},\n",
       "  'id': 400,\n",
       "  'max': 0.99722886,\n",
       "  'mean': 0.844378101746037,\n",
       "  'min': 0.007197533,\n",
       "  'name': 'portrait',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2411451504993836},\n",
       " {'description': 'Clarifai image recognition label: recreation',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.476038',\n",
       "   'description': 'Clarifai image recognition label: recreation',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 395,\n",
       "   'modality': None},\n",
       "  'id': 401,\n",
       "  'max': 0.9600388,\n",
       "  'mean': 0.5957422630771466,\n",
       "  'min': 0.0041213618,\n",
       "  'name': 'recreation',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.21562646744129524},\n",
       " {'description': 'Clarifai image recognition label: retro',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.489423',\n",
       "   'description': 'Clarifai image recognition label: retro',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 396,\n",
       "   'modality': None},\n",
       "  'id': 402,\n",
       "  'max': 0.98415625,\n",
       "  'mean': 0.3507805431747688,\n",
       "  'min': 0.0050255307,\n",
       "  'name': 'retro',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.18515305936409318},\n",
       " {'description': 'Clarifai image recognition label: road',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.502259',\n",
       "   'description': 'Clarifai image recognition label: road',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 397,\n",
       "   'modality': None},\n",
       "  'id': 403,\n",
       "  'max': 0.9603251,\n",
       "  'mean': 0.26041223895217963,\n",
       "  'min': 0.0053829066,\n",
       "  'name': 'road',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.20374416762996456},\n",
       " {'description': 'Clarifai image recognition label: room',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.514699',\n",
       "   'description': 'Clarifai image recognition label: room',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 398,\n",
       "   'modality': None},\n",
       "  'id': 404,\n",
       "  'max': 0.99610054,\n",
       "  'mean': 0.5814387529554161,\n",
       "  'min': 0.0036593396,\n",
       "  'name': 'room',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.28064650583760614},\n",
       " {'description': 'Clarifai image recognition label: simplicity',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.527033',\n",
       "   'description': 'Clarifai image recognition label: simplicity',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 399,\n",
       "   'modality': None},\n",
       "  'id': 405,\n",
       "  'max': 0.6765504,\n",
       "  'mean': 0.06666236569709379,\n",
       "  'min': 0.0004805692,\n",
       "  'name': 'simplicity',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.0776754947353194},\n",
       " {'description': 'Clarifai image recognition label: sky',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.540862',\n",
       "   'description': 'Clarifai image recognition label: sky',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 400,\n",
       "   'modality': None},\n",
       "  'id': 406,\n",
       "  'max': 0.9851012,\n",
       "  'mean': 0.1471785487709313,\n",
       "  'min': 0.0003505085,\n",
       "  'name': 'sky',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2291122143290606},\n",
       " {'description': 'Clarifai image recognition label: street',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.553307',\n",
       "   'description': 'Clarifai image recognition label: street',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 401,\n",
       "   'modality': None},\n",
       "  'id': 407,\n",
       "  'max': 0.988418,\n",
       "  'mean': 0.46232013185270804,\n",
       "  'min': 0.018030554,\n",
       "  'name': 'street',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.22586383052337397},\n",
       " {'description': 'Clarifai image recognition label: summer',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.566598',\n",
       "   'description': 'Clarifai image recognition label: summer',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 402,\n",
       "   'modality': None},\n",
       "  'id': 408,\n",
       "  'max': 0.94236994,\n",
       "  'mean': 0.19384575883361954,\n",
       "  'min': 0.0038420402,\n",
       "  'name': 'summer',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.20763347925907097},\n",
       " {'description': 'Clarifai image recognition label: sunset',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.579340',\n",
       "   'description': 'Clarifai image recognition label: sunset',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 403,\n",
       "   'modality': None},\n",
       "  'id': 409,\n",
       "  'max': 0.97328144,\n",
       "  'mean': 0.16775863003739763,\n",
       "  'min': 0.00037151726,\n",
       "  'name': 'sunset',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.21148904923276177},\n",
       " {'description': 'Clarifai image recognition label: technology',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.592358',\n",
       "   'description': 'Clarifai image recognition label: technology',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 404,\n",
       "   'modality': None},\n",
       "  'id': 410,\n",
       "  'max': 0.97835565,\n",
       "  'mean': 0.24044676777688243,\n",
       "  'min': 0.000977831,\n",
       "  'name': 'technology',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.1900024927788965},\n",
       " {'description': 'Clarifai image recognition label: text',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.605468',\n",
       "   'description': 'Clarifai image recognition label: text',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 405,\n",
       "   'modality': None},\n",
       "  'id': 411,\n",
       "  'max': 0.9659447,\n",
       "  'mean': 0.10805508501420079,\n",
       "  'min': 0.0018272972,\n",
       "  'name': 'text',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.13798721059023095},\n",
       " {'description': 'Clarifai image recognition label: travel',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.619087',\n",
       "   'description': 'Clarifai image recognition label: travel',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 406,\n",
       "   'modality': None},\n",
       "  'id': 412,\n",
       "  'max': 0.9898939,\n",
       "  'mean': 0.5070747072324967,\n",
       "  'min': 0.008747622,\n",
       "  'name': 'travel',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.24313791887776784},\n",
       " {'description': 'Clarifai image recognition label: two',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.632372',\n",
       "   'description': 'Clarifai image recognition label: two',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 407,\n",
       "   'modality': None},\n",
       "  'id': 413,\n",
       "  'max': 0.9880656,\n",
       "  'mean': 0.6198788831749009,\n",
       "  'min': 0.0030952923,\n",
       "  'name': 'two',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2606431238505689},\n",
       " {'description': 'Clarifai image recognition label: vehicle',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.645719',\n",
       "   'description': 'Clarifai image recognition label: vehicle',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 408,\n",
       "   'modality': None},\n",
       "  'id': 414,\n",
       "  'max': 0.9710667,\n",
       "  'mean': 0.28756021969227213,\n",
       "  'min': 0.0010548029,\n",
       "  'name': 'vehicle',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.22130476459792536},\n",
       " {'description': 'Clarifai image recognition label: vertical',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.658708',\n",
       "   'description': 'Clarifai image recognition label: vertical',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 409,\n",
       "   'modality': None},\n",
       "  'id': 415,\n",
       "  'max': 0.9831223,\n",
       "  'mean': 0.22431136762965653,\n",
       "  'min': 0.0031488794,\n",
       "  'name': 'vertical',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.17222935425572858},\n",
       " {'description': 'Clarifai image recognition label: water',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.671823',\n",
       "   'description': 'Clarifai image recognition label: water',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 410,\n",
       "   'modality': None},\n",
       "  'id': 416,\n",
       "  'max': 0.98332,\n",
       "  'mean': 0.19236254736895642,\n",
       "  'min': 0.0023856736,\n",
       "  'name': 'water',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2248826254667104},\n",
       " {'description': 'Clarifai image recognition label: wear',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.684708',\n",
       "   'description': 'Clarifai image recognition label: wear',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 411,\n",
       "   'modality': None},\n",
       "  'id': 417,\n",
       "  'max': 0.99394524,\n",
       "  'mean': 0.8033347456730515,\n",
       "  'min': 0.011061992,\n",
       "  'name': 'wear',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.20889379025199126},\n",
       " {'description': 'Clarifai image recognition label: wild',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.697743',\n",
       "   'description': 'Clarifai image recognition label: wild',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 412,\n",
       "   'modality': None},\n",
       "  'id': 418,\n",
       "  'max': 0.9104121,\n",
       "  'mean': 0.051217096484416115,\n",
       "  'min': 2.8655923e-05,\n",
       "  'name': 'wild',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.1091198436610003},\n",
       " {'description': 'Clarifai image recognition label: wildlife',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.710870',\n",
       "   'description': 'Clarifai image recognition label: wildlife',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 413,\n",
       "   'modality': None},\n",
       "  'id': 419,\n",
       "  'max': 0.9766924,\n",
       "  'mean': 0.06307652655077278,\n",
       "  'min': 0.000370618,\n",
       "  'name': 'wildlife',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.12709119950007128},\n",
       " {'description': 'Clarifai image recognition label: woman',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.724500',\n",
       "   'description': 'Clarifai image recognition label: woman',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 414,\n",
       "   'modality': None},\n",
       "  'id': 420,\n",
       "  'max': 0.9913015,\n",
       "  'mean': 0.8224397278936592,\n",
       "  'min': 0.01713263,\n",
       "  'name': 'woman',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.21667414226166393},\n",
       " {'description': 'Clarifai image recognition label: wood',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.737813',\n",
       "   'description': 'Clarifai image recognition label: wood',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 415,\n",
       "   'modality': None},\n",
       "  'id': 421,\n",
       "  'max': 0.9848612,\n",
       "  'mean': 0.32965608515257594,\n",
       "  'min': 0.0019894117,\n",
       "  'name': 'wood',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.26240319213054897},\n",
       " {'description': 'Clarifai image recognition label: writing',\n",
       "  'extracted_feature': {'created_at': '2018-04-19 20:25:09.751948',\n",
       "   'description': 'Clarifai image recognition label: writing',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 416,\n",
       "   'modality': None},\n",
       "  'id': 422,\n",
       "  'max': 0.9650652,\n",
       "  'mean': 0.08930379699914134,\n",
       "  'min': 0.0009408952,\n",
       "  'name': 'writing',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.11838302013784395},\n",
       " {'description': 'Speech (binarized, on or off)',\n",
       "  'extracted_feature': {'created_at': '2018-05-07 20:55:35.983007',\n",
       "   'description': 'Speech (binarized, on or off)',\n",
       "   'extractor_name': 'ComplexTextExtractor',\n",
       "   'id': 13327,\n",
       "   'modality': None},\n",
       "  'id': 12725,\n",
       "  'max': 1.0,\n",
       "  'mean': 1.0,\n",
       "  'min': 1.0,\n",
       "  'name': 'speech',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.0},\n",
       " {'description': 'Rigid-body transform parameter (translation)',\n",
       "  'id': 346,\n",
       "  'max': 2.11832,\n",
       "  'mean': 0.3938228497774811,\n",
       "  'min': 0.0,\n",
       "  'name': 'Z',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.47594311236994424},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 321,\n",
       "  'max': 0.0441725586,\n",
       "  'mean': 0.028065600178138576,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine00',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013572231710690115},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 322,\n",
       "  'max': 0.0441726104,\n",
       "  'mean': 0.02806558665337297,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine01',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013572259679249294},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 323,\n",
       "  'max': 0.0441725586,\n",
       "  'mean': 0.028065574773039104,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine02',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013572284248575922},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 324,\n",
       "  'max': 0.0441726104,\n",
       "  'mean': 0.028065563536256576,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine03',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013572307487153006},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 325,\n",
       "  'max': 0.0441713137,\n",
       "  'mean': 0.028065615320214957,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine04',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.01357220039602601},\n",
       " {'description': 'Esimated bulk-head motion',\n",
       "  'id': 308,\n",
       "  'max': 5.284783999999999,\n",
       "  'mean': 0.14395055588240632,\n",
       "  'min': 0.006293110000000038,\n",
       "  'name': 'FramewiseDisplacement',\n",
       "  'num_na': 17,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.1312134667336224},\n",
       " {'description': 'Global signal within whole-brain mask',\n",
       "  'id': 304,\n",
       "  'max': 25.949040834011164,\n",
       "  'mean': 1.3876365154748,\n",
       "  'min': 0.00018718020292918247,\n",
       "  'name': 'GlobalSignal',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 1.2987364536558048},\n",
       " {'description': 'Derivative of RMS variance over voxels, voxel-wise standardized',\n",
       "  'id': 307,\n",
       "  'max': 5.1815896,\n",
       "  'mean': 0.9877620757934191,\n",
       "  'min': 0.65068358,\n",
       "  'name': 'vx-wisestdDVARS',\n",
       "  'num_na': 17,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.15540323066026362},\n",
       " {'description': 'Average signal in White Matter mask',\n",
       "  'id': 303,\n",
       "  'max': 20.980982832333964,\n",
       "  'mean': 0.8031025217974358,\n",
       "  'min': 9.222792153285032e-05,\n",
       "  'name': 'WhiteMatter',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.7385401330594695},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 326,\n",
       "  'max': 0.0441726104,\n",
       "  'mean': 0.028065483425302996,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine05',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013572473151600638},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 327,\n",
       "  'max': 0.0441725586,\n",
       "  'mean': 0.028065415499085297,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine06',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013572613616973293},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 328,\n",
       "  'max': 0.0441726104,\n",
       "  'mean': 0.02806565600986737,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine07',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.01357211625184773},\n",
       " {'description': 'Derivative of RMS variance over voxels, non-standardized',\n",
       "  'id': 306,\n",
       "  'max': 112.79376221,\n",
       "  'mean': 23.439022621966238,\n",
       "  'min': 14.8468771,\n",
       "  'name': 'non-stdDVARS',\n",
       "  'num_na': 17,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 4.521080779421527},\n",
       " {'description': 'Derivative of RMS variance over voxels, standardized',\n",
       "  'id': 305,\n",
       "  'max': 5.50668669,\n",
       "  'mean': 1.2030794468429185,\n",
       "  'min': 0.65381312,\n",
       "  'name': 'stdDVARS',\n",
       "  'num_na': 17,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.20567275231666451},\n",
       " {'description': 'Average signal in CSF mask',\n",
       "  'id': 302,\n",
       "  'max': 57.91638585177842,\n",
       "  'mean': 2.714961967572705,\n",
       "  'min': 0.00014509166720744204,\n",
       "  'name': 'CSF',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 2.3890960475800913},\n",
       " {'description': 'Rigid-body transform parameter (rotation)',\n",
       "  'id': 347,\n",
       "  'max': 0.06689760000000002,\n",
       "  'mean': 0.005729821219321404,\n",
       "  'min': 0.0,\n",
       "  'name': 'RotX',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.006483074655431473},\n",
       " {'description': 'Rigid-body transform parameter (rotation)',\n",
       "  'id': 348,\n",
       "  'max': 0.0292126,\n",
       "  'mean': 0.004179903328463298,\n",
       "  'min': 0.0,\n",
       "  'name': 'RotY',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.003927085874888819},\n",
       " {'description': 'Rigid-body transform parameter (rotation)',\n",
       "  'id': 349,\n",
       "  'max': 0.018571599999999997,\n",
       "  'mean': 0.0020944766176230847,\n",
       "  'min': 0.0,\n",
       "  'name': 'RotZ',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.0022780348780867435},\n",
       " {'description': 'Rigid-body transform parameter (translation)',\n",
       "  'id': 344,\n",
       "  'max': 1.3577299999999999,\n",
       "  'mean': 0.20402584233395638,\n",
       "  'min': 0.0,\n",
       "  'name': 'X',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.20988020104828228},\n",
       " {'description': 'Rigid-body transform parameter (translation)',\n",
       "  'id': 345,\n",
       "  'max': 1.4869999999999999,\n",
       "  'mean': 0.17122677339757444,\n",
       "  'min': 0.0,\n",
       "  'name': 'Y',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.21588810849365808},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 329,\n",
       "  'max': 0.0441725586,\n",
       "  'mean': 0.028065713891470386,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine08',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013571996548072292},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 330,\n",
       "  'max': 0.0441726104,\n",
       "  'mean': 0.02806523331008461,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine09',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013572990363014634},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 331,\n",
       "  'max': 0.0441725586,\n",
       "  'mean': 0.028065600178138576,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine10',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013572231710690115},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 332,\n",
       "  'max': 0.0441726104,\n",
       "  'mean': 0.02806564579819346,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine11',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013572137372767551},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 314,\n",
       "  'max': 0.2785439576,\n",
       "  'mean': 0.024553888415235536,\n",
       "  'min': 0.0,\n",
       "  'name': 'tCompCor05',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.019209386123395972},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 333,\n",
       "  'max': 0.0441725586,\n",
       "  'mean': 0.028065167993962956,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine12',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013573125426984878},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 334,\n",
       "  'max': 0.0441726104,\n",
       "  'mean': 0.028065678993036816,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine13',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013572068719795995},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 335,\n",
       "  'max': 0.0441713137,\n",
       "  'mean': 0.028065589915115482,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine14',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013572252934061382},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 336,\n",
       "  'max': 0.0441726104,\n",
       "  'mean': 0.02806565600986737,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine15',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.01357211625184773},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 337,\n",
       "  'max': 0.0441725586,\n",
       "  'mean': 0.028065600178138576,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine16',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013572231710690115},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 338,\n",
       "  'max': 0.0441726104,\n",
       "  'mean': 0.028064370435044592,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine17',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.01357477451051993},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 339,\n",
       "  'max': 0.0441725586,\n",
       "  'mean': 0.028066295825966155,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine18',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013570793025505703},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 340,\n",
       "  'max': 0.0441726104,\n",
       "  'mean': 0.028065763430288132,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine19',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013571894104032662},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 341,\n",
       "  'max': 0.0441725586,\n",
       "  'mean': 0.028063912560919276,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine20',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013575721129119792},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 342,\n",
       "  'max': 0.0441726104,\n",
       "  'mean': 0.02806558665337297,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine21',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013572259679249294},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 343,\n",
       "  'max': 0.0441725586,\n",
       "  'mean': 0.028065600178138576,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine22',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.013572231710690115},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 309,\n",
       "  'max': 0.1657270568,\n",
       "  'mean': 0.025288772768282643,\n",
       "  'min': 0.0,\n",
       "  'name': 'tCompCor00',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.018231012842792008},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 310,\n",
       "  'max': 0.3047753905,\n",
       "  'mean': 0.025118379544591812,\n",
       "  'min': 0.0,\n",
       "  'name': 'tCompCor01',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.0184650848227364},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 311,\n",
       "  'max': 0.3054434761,\n",
       "  'mean': 0.02522418460689458,\n",
       "  'min': 0.0,\n",
       "  'name': 'tCompCor02',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.018320277149897576},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 312,\n",
       "  'max': 0.4729968389,\n",
       "  'mean': 0.023905295614921107,\n",
       "  'min': 0.0,\n",
       "  'name': 'tCompCor03',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.020010811828954426},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 315,\n",
       "  'max': 0.4225730362,\n",
       "  'mean': 0.024022809899239654,\n",
       "  'min': 0.0,\n",
       "  'name': 'aCompCor00',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.01986957551180129},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 316,\n",
       "  'max': 0.6517820834,\n",
       "  'mean': 0.024779999376783674,\n",
       "  'min': 0.0,\n",
       "  'name': 'aCompCor01',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.018916790020544083},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 317,\n",
       "  'max': 0.2682092336,\n",
       "  'mean': 0.02443605821989481,\n",
       "  'min': 0.0,\n",
       "  'name': 'aCompCor02',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.019359063516691453},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 318,\n",
       "  'max': 0.2673553865,\n",
       "  'mean': 0.024255689354636404,\n",
       "  'min': 0.0,\n",
       "  'name': 'aCompCor03',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.01958459388435956},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 319,\n",
       "  'max': 0.3897808927000001,\n",
       "  'mean': 0.02431032167940773,\n",
       "  'min': 0.0,\n",
       "  'name': 'aCompCor04',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.01951673363654824},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 320,\n",
       "  'max': 0.2744528603,\n",
       "  'mean': 0.024647104087988796,\n",
       "  'min': 0.0,\n",
       "  'name': 'aCompCor05',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.01908962936860354}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.predictors.get(run_id=run_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bunch of useful information to help me choose some features! Let's keep it simple and go with 'face_detectionConfidence' and 'FramewiseDisplacement':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[354, 308]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ids = [r['id'] for r in api.predictors.get(run_id=run_ids) if r['name'] in \\\n",
    "            ['face_detectionConfidence', 'FramewiseDisplacement']]\n",
    "pred_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build an analysis. For this, we can use the `Analysis` class, which makes it easy to build an Analysis locally, by mirroring the Analysis representation on the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis = api.analyses.create_analysis(dataset_id=5, name='My new analysis!', predictors=pred_ids, runs=run_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_analysis` returns an object, which has been registered to the API. We can tell, because analyses are assigned a unique id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MaO1w'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.hash_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-09-06T23:5'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some properties are read-only and came from the server\n",
    "analysis.created_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can edit this Analysis object to fill in any other Analysis details, and push them to the Neuroscout API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis.description = \"This is my analysis, and it's probably the best\"\n",
    "analysis.push()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now let's add a BIDS-Model to represent the analysis we want to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis.model = {\n",
    "    \"blocks\": [\n",
    "      {\n",
    "        \"auto_contrasts\": True,\n",
    "        \"contrasts\": [],\n",
    "        \"level\": \"run\",\n",
    "        \"model\": {\n",
    "          \"HRF_variables\": [\n",
    "            \"face_detectionConfidence\"\n",
    "          ],\n",
    "          \"variables\": [\n",
    "            \"face_detectionConfidence\",\n",
    "            \"FramewiseDisplacement\"\n",
    "          ]\n",
    "        },\n",
    "        \"transformations\": []\n",
    "      },\n",
    "      {\n",
    "        \"auto_contrasts\": True,\n",
    "        \"level\": \"dataset\"\n",
    "      }\n",
    "    ],\n",
    "    \"input\": {\n",
    "      \"subject\": [\n",
    "        \"28\",\n",
    "        \"29\"\n",
    "      ],\n",
    "      \"task\": \"MerlinMovie\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blocks': [{'auto_contrasts': True,\n",
       "   'contrasts': [],\n",
       "   'level': 'run',\n",
       "   'model': {'HRF_variables': ['face_detectionConfidence'],\n",
       "    'variables': ['face_detectionConfidence', 'FramewiseDisplacement']},\n",
       "   'transformations': []},\n",
       "  {'auto_contrasts': True, 'level': 'dataset'}],\n",
       " 'input': {'subject': ['28', '29'], 'task': 'MerlinMovie'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.push()\n",
    "analysis.pull()\n",
    "analysis.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the analysis\n",
    "Now that we have created and design an analysis we can ask the Neuroscout API to compile and verify this is a valid analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TR': 1.5,\n",
       " 'compile_traceback': '',\n",
       " 'compiled_at': None,\n",
       " 'created_at': '2018-09-06T23:5',\n",
       " 'dataset_id': 5,\n",
       " 'description': \"This is my analysis, and it's probably the best\",\n",
       " 'hash_id': 'MaO1w',\n",
       " 'model': {'blocks': [{'auto_contrasts': True,\n",
       "    'contrasts': [],\n",
       "    'level': 'run',\n",
       "    'model': {'HRF_variables': ['face_detectionConfidence'],\n",
       "     'variables': ['face_detectionConfidence', 'FramewiseDisplacement']},\n",
       "    'transformations': []},\n",
       "   {'auto_contrasts': True, 'level': 'dataset'}],\n",
       "  'input': {'subject': ['28', '29'], 'task': 'MerlinMovie'}},\n",
       " 'modified_at': '2018-09-06T23:5',\n",
       " 'name': 'My new analysis!',\n",
       " 'parent_id': None,\n",
       " 'predictions': '',\n",
       " 'predictors': [354, 308],\n",
       " 'private': True,\n",
       " 'runs': [126, 127],\n",
       " 'status': 'PENDING',\n",
       " 'task_name': 'MerlinMovie'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compile_traceback': '', 'status': 'PASSED'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our analysis passed with no errors. We can now run our analysis using the `neuroscout-cli`. \n",
    "\n",
    "For more information on the `neuroscout-cli`, see here: https://github.com/neuroscout/neuroscout-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloning our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've gone off and run our analysis, we realized we want to make some changes. In this case, I want to run this analysis with more subjects. \n",
    "\n",
    "With Neuroscout this is easy, because I simply clone my previous analysis, and take off from I left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 124,\n",
       " 125,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_analysis = analysis.clone()\n",
    "new_analysis.hash_id\n",
    "new_analysis.runs = [r['id'] for r in api.runs.get(dataset_id=dataset['id'])]\n",
    "new_analysis.runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TR': 1.5,\n",
       " 'compile_traceback': '',\n",
       " 'compiled_at': None,\n",
       " 'created_at': '2018-09-06T23:5',\n",
       " 'dataset_id': 5,\n",
       " 'description': \"This is my analysis, and it's probably the best\",\n",
       " 'hash_id': 'A27pM',\n",
       " 'model': {'blocks': [{'auto_contrasts': True,\n",
       "    'contrasts': [],\n",
       "    'level': 'run',\n",
       "    'model': {'HRF_variables': ['face_detectionConfidence'],\n",
       "     'variables': ['face_detectionConfidence', 'FramewiseDisplacement']},\n",
       "    'transformations': []},\n",
       "   {'auto_contrasts': True, 'level': 'dataset'}],\n",
       "  'input': {'subject': ['28', '29'], 'task': 'MerlinMovie'}},\n",
       " 'modified_at': '2018-09-06T23:5',\n",
       " 'name': 'My new analysis!',\n",
       " 'parent_id': None,\n",
       " 'predictions': '',\n",
       " 'predictors': [354, 308],\n",
       " 'private': True,\n",
       " 'runs': [126,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  117,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  121,\n",
       "  122,\n",
       "  124,\n",
       "  125,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  134],\n",
       " 'status': 'PENDING',\n",
       " 'task_name': 'MerlinMovie'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_analysis.push()\n",
    "new_analysis.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compile_traceback': '', 'status': 'PASSED'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_analysis.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, since this analysis also passed, I can easily run this forked version using the `neuroscout-cli`. If you have any questions on how to use the Neuroscout API, please see the API's Swagger Documentation, which covers all possible routes and parameters: https://alpha.neuroscout.org/swagger-ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
