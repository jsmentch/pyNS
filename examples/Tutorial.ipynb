{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to pyNS \n",
    "pyNS is a Python library to programmatically access the Neuroscout API. pyNS let's you query the API and create analyses, without having to mess around with buildling any JSON requests yourself.\n",
    "\n",
    "In this tutorial, I'll demonstrate how to query the API to create your own analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyns import Neuroscout\n",
    "api = Neuroscout('user@university.edu', 'yourpassword')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Neuroscout` object will be your main entry point to the API. You can instantiate this object without any credentials to access public API routes, or preferably with your Neuroscout credentials to be able to create and save your analyses. The `Neuroscout` object has links to each main API route, and each of these links implements the standard HTTP verbs that are suppoted by each route, such as `datasets`, `runs`, `predictors`, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying datasets and runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'description': {'Authors': ['Alexander, L. et al.'],\n",
       "   'BIDSVersion': '1.0.2',\n",
       "   'Name': 'Healthy_Brain_Network'},\n",
       "  'id': 8,\n",
       "  'mimetypes': ['audio/x-wav', 'image/png', 'text/plain', 'video/x-matroska'],\n",
       "  'name': 'HealthyBrainNetwork',\n",
       "  'runs': [216,\n",
       "   200,\n",
       "   202,\n",
       "   204,\n",
       "   205,\n",
       "   206,\n",
       "   208,\n",
       "   209,\n",
       "   210,\n",
       "   211,\n",
       "   212,\n",
       "   213,\n",
       "   214,\n",
       "   215,\n",
       "   217,\n",
       "   218,\n",
       "   219,\n",
       "   220,\n",
       "   221,\n",
       "   222,\n",
       "   223,\n",
       "   224,\n",
       "   225,\n",
       "   226,\n",
       "   227,\n",
       "   228,\n",
       "   229,\n",
       "   230,\n",
       "   231,\n",
       "   399,\n",
       "   400,\n",
       "   401,\n",
       "   402,\n",
       "   403,\n",
       "   404,\n",
       "   405,\n",
       "   406,\n",
       "   407,\n",
       "   408,\n",
       "   409,\n",
       "   410,\n",
       "   411,\n",
       "   412,\n",
       "   413,\n",
       "   414,\n",
       "   415,\n",
       "   416,\n",
       "   417,\n",
       "   418,\n",
       "   419,\n",
       "   420,\n",
       "   421,\n",
       "   422,\n",
       "   423,\n",
       "   424,\n",
       "   425,\n",
       "   426,\n",
       "   427,\n",
       "   428,\n",
       "   429],\n",
       "  'summary': 'Movie watching paradigms from the Healthy Brain Network brain development study',\n",
       "  'tasks': [{'id': 7,\n",
       "    'name': 'movieDM',\n",
       "    'num_runs': 60,\n",
       "    'summary': 'AV Presentation: Despicable Me'}],\n",
       "  'url': 'http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/'},\n",
       " {'description': {'Acknowledgments': 'We thank Jason Gors, Kelsey G. Wheeler J. Swaroop Guntupalli, Matteo Visconti di Oleggio Castello, M. Ida Gobbini, Terry Sacket, and the rest of the DBIC (Dartmouth Brain Imaging Center) personnel for assistance in data collection/curation.',\n",
       "   'Authors': ['Samuel A. Nastase',\n",
       "    'Yaroslav O. Halchenko',\n",
       "    'Andrew C. Connolly',\n",
       "    'James V. Haxby'],\n",
       "   'BIDSVersion': '1.0.1',\n",
       "   'Funding': ['5R01MH075706', 'F32MH085433-01A1', 'NSF1129764'],\n",
       "   'HowToAcknowledge': 'If you find this data set useful, please cite the following paper: Nastase, S. A., Connolly, A. C., Oosterhof, N. N., Halchenko, Y. O., Guntupalli, J. S., di Oleggio Castello, M. V., Gors, J., Gobbini, M. I., & Haxby, J. V. (2017). Attention selectively reshapes the geometry of distributed semantic representation. Cerebral Cortex.',\n",
       "   'License': 'PDDL',\n",
       "   'Name': 'Neural responses to naturalistic clips of animals'},\n",
       "  'id': 9,\n",
       "  'mimetypes': ['audio/x-wav', 'image/png', 'text/plain', 'video/x-matroska'],\n",
       "  'name': 'Life',\n",
       "  'runs': [235,\n",
       "   236,\n",
       "   237,\n",
       "   238,\n",
       "   239,\n",
       "   240,\n",
       "   241,\n",
       "   242,\n",
       "   243,\n",
       "   244,\n",
       "   245,\n",
       "   246,\n",
       "   247,\n",
       "   248,\n",
       "   249,\n",
       "   250,\n",
       "   251,\n",
       "   252,\n",
       "   253,\n",
       "   254,\n",
       "   255,\n",
       "   256,\n",
       "   257,\n",
       "   258,\n",
       "   259,\n",
       "   260,\n",
       "   261,\n",
       "   262,\n",
       "   263,\n",
       "   264,\n",
       "   265,\n",
       "   266,\n",
       "   267,\n",
       "   268,\n",
       "   269,\n",
       "   270,\n",
       "   271,\n",
       "   272,\n",
       "   273,\n",
       "   274,\n",
       "   275,\n",
       "   276,\n",
       "   277,\n",
       "   278,\n",
       "   279,\n",
       "   280,\n",
       "   281,\n",
       "   282,\n",
       "   283,\n",
       "   284,\n",
       "   285,\n",
       "   286,\n",
       "   287,\n",
       "   288,\n",
       "   289,\n",
       "   290,\n",
       "   291,\n",
       "   292,\n",
       "   293,\n",
       "   294,\n",
       "   295,\n",
       "   296,\n",
       "   297,\n",
       "   298,\n",
       "   299,\n",
       "   300,\n",
       "   301,\n",
       "   302,\n",
       "   303,\n",
       "   304,\n",
       "   305,\n",
       "   306,\n",
       "   307,\n",
       "   308,\n",
       "   309,\n",
       "   310],\n",
       "  'summary': 'Four segments of the Life nature documentary narrated by David Attenborough',\n",
       "  'tasks': [{'id': 8,\n",
       "    'name': 'life',\n",
       "    'num_runs': 76,\n",
       "    'summary': 'AV Presentation'}],\n",
       "  'url': 'http://datasets.datalad.org/?dir=/labs/haxby/life'},\n",
       " {'description': {'Acknowledgements': 'We thanks Courtney Rogers and Jason Gors for help with collecting the data, and Steven Spielberg and George Lucas for such a wonderful movie.',\n",
       "   'Authors': ['J. Swaroop Guntupalli',\n",
       "    'Yaroslav O. Halchenko',\n",
       "    'James V. Haxby'],\n",
       "   'BIDSVersion': '1.0.1',\n",
       "   'Funding': 'Funding was provided by National Institutes of Mental Health grant 5R01MH075706 (Haxby), and by a graduate fellowship from the Neukom Institute for Computational Sciences at Dartmouth (Guntupalli).',\n",
       "   'HowToAcknowledge': 'Please cite Haxby et al.(2011). doi:10.1016/j.neuron.2011.08.026',\n",
       "   'License': 'PDDL',\n",
       "   'Name': 'Dartmouth Raiders Dataset',\n",
       "   'ReferencesAndLinks': ['doi:10.1016/j.neuron.2011.08.026']},\n",
       "  'id': 10,\n",
       "  'mimetypes': ['audio/x-wav', 'image/png', 'text/plain', 'video/x-m4v'],\n",
       "  'name': 'Raiders',\n",
       "  'runs': [333,\n",
       "   324,\n",
       "   343,\n",
       "   334,\n",
       "   332,\n",
       "   327,\n",
       "   328,\n",
       "   331,\n",
       "   341,\n",
       "   344,\n",
       "   329,\n",
       "   330,\n",
       "   322,\n",
       "   336,\n",
       "   335,\n",
       "   325,\n",
       "   323,\n",
       "   321,\n",
       "   345,\n",
       "   359,\n",
       "   350,\n",
       "   362,\n",
       "   367,\n",
       "   348,\n",
       "   358,\n",
       "   361,\n",
       "   360,\n",
       "   356,\n",
       "   355,\n",
       "   353,\n",
       "   346,\n",
       "   351,\n",
       "   363,\n",
       "   354,\n",
       "   347,\n",
       "   349,\n",
       "   357,\n",
       "   383,\n",
       "   395,\n",
       "   377,\n",
       "   380,\n",
       "   376,\n",
       "   372,\n",
       "   375,\n",
       "   394,\n",
       "   379,\n",
       "   384,\n",
       "   391,\n",
       "   373,\n",
       "   389,\n",
       "   386,\n",
       "   390,\n",
       "   371,\n",
       "   385,\n",
       "   387,\n",
       "   378,\n",
       "   381,\n",
       "   392,\n",
       "   382,\n",
       "   368,\n",
       "   326,\n",
       "   397,\n",
       "   398,\n",
       "   396,\n",
       "   388,\n",
       "   352,\n",
       "   393,\n",
       "   338,\n",
       "   366,\n",
       "   364,\n",
       "   369,\n",
       "   374,\n",
       "   370,\n",
       "   339,\n",
       "   340,\n",
       "   342,\n",
       "   337,\n",
       "   365,\n",
       "   311,\n",
       "   313,\n",
       "   314,\n",
       "   320,\n",
       "   319,\n",
       "   312,\n",
       "   315,\n",
       "   317,\n",
       "   318,\n",
       "   316],\n",
       "  'summary': 'Raiders of the Lost Art movie watching paradigm',\n",
       "  'tasks': [{'id': 9,\n",
       "    'name': 'raiders',\n",
       "    'num_runs': 88,\n",
       "    'summary': 'AV Presentation: Raiders of the Lost Ark'}],\n",
       "  'url': 'https://github.com/HaxbyLab/raiders_data'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.datasets.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This request returns a list of two datasets, with information about the dataset, as well as the run IDs associated with this dataset. Let's focus on the dataset, `life`\n",
    "\n",
    "If we want more information on the specific runs within this dataset, we can query the `runs` route, using the dataset_id associated with `life`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 235,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000001',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 236,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000001',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 237,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000001',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 238,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000001',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 239,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000005',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 240,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000005',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 241,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000005',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 242,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000005',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 243,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000006',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 244,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000006',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 245,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000006',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 246,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000006',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 247,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000009',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 248,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000009',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 249,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000009',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 250,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000009',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 251,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000012',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 252,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000012',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 253,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000012',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 254,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000012',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 255,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000014',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 256,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000014',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 257,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000014',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 258,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000014',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 259,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000017',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 260,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000017',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 261,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000017',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 262,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000017',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 263,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000019',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 264,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000019',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 265,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000019',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 266,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000019',\n",
       "  'task': 8},\n",
       " {'acquisition': '338vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 845.0,\n",
       "  'id': 267,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000020',\n",
       "  'task': 8},\n",
       " {'acquisition': '366vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 915.0,\n",
       "  'id': 268,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000020',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 269,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000020',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 270,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000020',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 271,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000024',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 272,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000024',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 273,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000024',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 274,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000024',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 275,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000027',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 276,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000027',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 277,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000027',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 278,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000027',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 279,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000031',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 280,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000031',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 281,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000031',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 282,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000031',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 283,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000032',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 284,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000032',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 285,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000032',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 286,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000032',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 287,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000033',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 288,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000033',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 289,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000033',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 290,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000033',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 291,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000034',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 292,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000034',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 293,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000034',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 294,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000034',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 295,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000036',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 296,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000036',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 297,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000036',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 298,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000036',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 299,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000037',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 300,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000037',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 301,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000037',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 302,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000037',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 303,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000038',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 304,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000038',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 305,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000038',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 306,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000038',\n",
       "  'task': 8},\n",
       " {'acquisition': '346vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 865.0,\n",
       "  'id': 307,\n",
       "  'number': 2,\n",
       "  'session': None,\n",
       "  'subject': 'rid000041',\n",
       "  'task': 8},\n",
       " {'acquisition': '374vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 935.0,\n",
       "  'id': 308,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'rid000041',\n",
       "  'task': 8},\n",
       " {'acquisition': '377vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 942.5,\n",
       "  'id': 309,\n",
       "  'number': 3,\n",
       "  'session': None,\n",
       "  'subject': 'rid000041',\n",
       "  'task': 8},\n",
       " {'acquisition': '412vol',\n",
       "  'dataset_id': 9,\n",
       "  'duration': 1030.0,\n",
       "  'id': 310,\n",
       "  'number': 4,\n",
       "  'session': None,\n",
       "  'subject': 'rid000041',\n",
       "  'task': 8}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = api.datasets.get()[1]\n",
    "api.runs.get(dataset_id=dataset['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this information, we can decide which runs to focus on for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the predictors associated with this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'description': 'Clarifai image recognition label: horizontal',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.995043',\n",
       "   'description': 'Clarifai image recognition label: horizontal',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13660,\n",
       "   'modality': None},\n",
       "  'id': 12800,\n",
       "  'max': 0.95819473,\n",
       "  'mean': 0.4212714761726175,\n",
       "  'min': 0.0149346925,\n",
       "  'name': 'horizontal',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.19377647775118148},\n",
       " {'description': 'Clarifai image recognition label: hand',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.976167',\n",
       "   'description': 'Clarifai image recognition label: hand',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13658,\n",
       "   'modality': None},\n",
       "  'id': 12798,\n",
       "  'max': 0.6226746,\n",
       "  'mean': 0.039579114216090575,\n",
       "  'min': 1.0978953e-05,\n",
       "  'name': 'hand',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.07129718248813187},\n",
       " {'description': 'Clarifai image recognition label: desktop',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.901265',\n",
       "   'description': 'Clarifai image recognition label: desktop',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13650,\n",
       "   'modality': None},\n",
       "  'id': 12790,\n",
       "  'max': 0.9987119,\n",
       "  'mean': 0.5620136741590969,\n",
       "  'min': 0.010557182,\n",
       "  'name': 'desktop',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.28081970597675976},\n",
       " {'description': 'Clarifai image recognition label: empty',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.910151',\n",
       "   'description': 'Clarifai image recognition label: empty',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13651,\n",
       "   'modality': None},\n",
       "  'id': 12791,\n",
       "  'max': 0.916003,\n",
       "  'mean': 0.0850558577887687,\n",
       "  'min': 0.00032239628,\n",
       "  'name': 'empty',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.12887460219838945},\n",
       " {'description': 'Clarifai image recognition label: equipment',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.919530',\n",
       "   'description': 'Clarifai image recognition label: equipment',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13652,\n",
       "   'modality': None},\n",
       "  'id': 12792,\n",
       "  'max': 0.87917185,\n",
       "  'mean': 0.02358216486178262,\n",
       "  'min': 0.00020280929,\n",
       "  'name': 'equipment',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.04773007019775252},\n",
       " {'description': 'Clarifai image recognition label: face',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.929665',\n",
       "   'description': 'Clarifai image recognition label: face',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13653,\n",
       "   'modality': None},\n",
       "  'id': 12793,\n",
       "  'max': 0.9816723,\n",
       "  'mean': 0.12821662723943344,\n",
       "  'min': 4.3318767e-05,\n",
       "  'name': 'face',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.19947052701601856},\n",
       " {'description': 'Clarifai image recognition label: family',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.938888',\n",
       "   'description': 'Clarifai image recognition label: family',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13654,\n",
       "   'modality': None},\n",
       "  'id': 12794,\n",
       "  'max': 0.91893244,\n",
       "  'mean': 0.21850351074297716,\n",
       "  'min': 0.005083178,\n",
       "  'name': 'family',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.19450318552087648},\n",
       " {'description': 'Clarifai image recognition label: fashion',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.948279',\n",
       "   'description': 'Clarifai image recognition label: fashion',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13655,\n",
       "   'modality': None},\n",
       "  'id': 12795,\n",
       "  'max': 0.9137747,\n",
       "  'mean': 0.03635153971579627,\n",
       "  'min': 4.5448818e-05,\n",
       "  'name': 'fashion',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.08927305667913252},\n",
       " {'description': 'Clarifai image recognition label: furniture',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.957723',\n",
       "   'description': 'Clarifai image recognition label: furniture',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13656,\n",
       "   'modality': None},\n",
       "  'id': 12796,\n",
       "  'max': 0.77261174,\n",
       "  'mean': 0.021861920187064846,\n",
       "  'min': 0.00019758008,\n",
       "  'name': 'furniture',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.047295038180698704},\n",
       " {'description': 'Clarifai image recognition label: girl',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.966795',\n",
       "   'description': 'Clarifai image recognition label: girl',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13657,\n",
       "   'modality': None},\n",
       "  'id': 12797,\n",
       "  'max': 0.96516025,\n",
       "  'mean': 0.05870728899826884,\n",
       "  'min': 6.5392676e-05,\n",
       "  'name': 'girl',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.11831237044249071},\n",
       " {'description': 'Clarifai image recognition label: retro',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.156132',\n",
       "   'description': 'Clarifai image recognition label: retro',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13677,\n",
       "   'modality': None},\n",
       "  'id': 12817,\n",
       "  'max': 0.97199535,\n",
       "  'mean': 0.08106677640658703,\n",
       "  'min': 0.0004498709,\n",
       "  'name': 'retro',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.1316184038122461},\n",
       " {'description': 'Clarifai image recognition label: road',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.167774',\n",
       "   'description': 'Clarifai image recognition label: road',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13678,\n",
       "   'modality': None},\n",
       "  'id': 12818,\n",
       "  'max': 0.9257599,\n",
       "  'mean': 0.157733697867288,\n",
       "  'min': 0.0009754362,\n",
       "  'name': 'road',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.17585557410439806},\n",
       " {'description': 'Clarifai image recognition label: room',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.176743',\n",
       "   'description': 'Clarifai image recognition label: room',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13679,\n",
       "   'modality': None},\n",
       "  'id': 12819,\n",
       "  'max': 0.5643239,\n",
       "  'mean': 0.015877870688113152,\n",
       "  'min': 4.986238e-05,\n",
       "  'name': 'room',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.036432272592446996},\n",
       " {'description': 'Clarifai image recognition label: simplicity',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.186760',\n",
       "   'description': 'Clarifai image recognition label: simplicity',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13680,\n",
       "   'modality': None},\n",
       "  'id': 12820,\n",
       "  'max': 0.9080779,\n",
       "  'mean': 0.1181220934,\n",
       "  'min': 0.0010515818,\n",
       "  'name': 'simplicity',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.13010623535830274},\n",
       " {'description': 'Clarifai image recognition label: sky',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.196242',\n",
       "   'description': 'Clarifai image recognition label: sky',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13681,\n",
       "   'modality': None},\n",
       "  'id': 12821,\n",
       "  'max': 0.99837804,\n",
       "  'mean': 0.44320708506804934,\n",
       "  'min': 0.003824308,\n",
       "  'name': 'sky',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.3022562952014278},\n",
       " {'description': 'Clarifai image recognition label: street',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.205590',\n",
       "   'description': 'Clarifai image recognition label: street',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13682,\n",
       "   'modality': None},\n",
       "  'id': 12822,\n",
       "  'max': 0.863019,\n",
       "  'mean': 0.07917092601578105,\n",
       "  'min': 0.0004992766,\n",
       "  'name': 'street',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.11341690113352523},\n",
       " {'description': 'Clarifai image recognition label: action',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.726065',\n",
       "   'description': 'Clarifai image recognition label: action',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13632,\n",
       "   'modality': None},\n",
       "  'id': 12772,\n",
       "  'max': 0.9992758,\n",
       "  'mean': 0.27167737192482544,\n",
       "  'min': 0.00028673618,\n",
       "  'name': 'action',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.31140956651031376},\n",
       " {'description': 'Average signal in CSF mask',\n",
       "  'id': 12729,\n",
       "  'max': 1795.4219970703125,\n",
       "  'mean': 1445.1096857480259,\n",
       "  'min': 903.2899780273438,\n",
       "  'name': 'CSF',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 171.85742187741772},\n",
       " {'description': 'Likelihood of nudity, pornographic images or cartoons, or sexual activities',\n",
       "  'extracted_feature': {'created_at': '2018-05-10 04:41:47.611993',\n",
       "   'description': 'Likelihood of nudity, pornographic images or cartoons, or sexual activities',\n",
       "   'extractor_name': 'GoogleVisionAPISafeSearchExtractor',\n",
       "   'id': 78093,\n",
       "   'modality': None},\n",
       "  'id': 12852,\n",
       "  'max': None,\n",
       "  'mean': None,\n",
       "  'min': None,\n",
       "  'name': 'adult',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': None},\n",
       " {'description': \"Likelihood that an modification was made to the image's canonical version to make it appear funny or offensive\",\n",
       "  'extracted_feature': {'created_at': '2018-05-10 04:41:47.795017',\n",
       "   'description': \"Likelihood that an modification was made to the image's canonical version to make it appear funny or offensive\",\n",
       "   'extractor_name': 'GoogleVisionAPISafeSearchExtractor',\n",
       "   'id': 78094,\n",
       "   'modality': None},\n",
       "  'id': 12853,\n",
       "  'max': None,\n",
       "  'mean': None,\n",
       "  'min': None,\n",
       "  'name': 'spoof',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': None},\n",
       " {'description': 'Likelihood that this is a medical image',\n",
       "  'extracted_feature': {'created_at': '2018-05-10 04:41:47.981470',\n",
       "   'description': 'Likelihood that this is a medical image',\n",
       "   'extractor_name': 'GoogleVisionAPISafeSearchExtractor',\n",
       "   'id': 78095,\n",
       "   'modality': None},\n",
       "  'id': 12854,\n",
       "  'max': None,\n",
       "  'mean': None,\n",
       "  'min': None,\n",
       "  'name': 'medical',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': None},\n",
       " {'description': 'Likelihood that this image contains violent content',\n",
       "  'extracted_feature': {'created_at': '2018-05-10 04:41:48.171900',\n",
       "   'description': 'Likelihood that this image contains violent content',\n",
       "   'extractor_name': 'GoogleVisionAPISafeSearchExtractor',\n",
       "   'id': 78096,\n",
       "   'modality': None},\n",
       "  'id': 12855,\n",
       "  'max': None,\n",
       "  'mean': None,\n",
       "  'min': None,\n",
       "  'name': 'violence',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': None},\n",
       " {'description': 'Lexical frequency of words in corpus of 51 million words (log)',\n",
       "  'extracted_feature': {'created_at': '2018-06-01 22:05:18.738020',\n",
       "   'description': 'Lexical frequency of words in corpus of 51 million words (log)',\n",
       "   'extractor_name': 'PredefinedDictionaryExtractor',\n",
       "   'id': 84271,\n",
       "   'modality': None},\n",
       "  'id': 12915,\n",
       "  'max': 6.329339698310973,\n",
       "  'mean': 4.390135530016625,\n",
       "  'min': 0.4771212547196624,\n",
       "  'name': 'subtlexusfrequency_Lg10WF',\n",
       "  'num_na': 2299,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 1.3950200146519562},\n",
       " {'description': 'Clarifai image recognition label: text',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.242162',\n",
       "   'description': 'Clarifai image recognition label: text',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13686,\n",
       "   'modality': None},\n",
       "  'id': 12826,\n",
       "  'max': 0.7681608,\n",
       "  'mean': 0.014939568466228669,\n",
       "  'min': 7.107134e-05,\n",
       "  'name': 'text',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.03854388554638315},\n",
       " {'description': 'Clarifai image recognition label: travel',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.251286',\n",
       "   'description': 'Clarifai image recognition label: travel',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13687,\n",
       "   'modality': None},\n",
       "  'id': 12827,\n",
       "  'max': 0.99308777,\n",
       "  'mean': 0.7032078884502494,\n",
       "  'min': 0.02876426,\n",
       "  'name': 'travel',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.23737884172128282},\n",
       " {'description': 'Clarifai image recognition label: two',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.263803',\n",
       "   'description': 'Clarifai image recognition label: two',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13688,\n",
       "   'modality': None},\n",
       "  'id': 12828,\n",
       "  'max': 0.97469425,\n",
       "  'mean': 0.3875568905341402,\n",
       "  'min': 0.00069794484,\n",
       "  'name': 'two',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2549039815275899},\n",
       " {'description': 'Clarifai image recognition label: vehicle',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.274439',\n",
       "   'description': 'Clarifai image recognition label: vehicle',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13689,\n",
       "   'modality': None},\n",
       "  'id': 12829,\n",
       "  'max': 0.9654676,\n",
       "  'mean': 0.18474857009777895,\n",
       "  'min': 0.00022574623,\n",
       "  'name': 'vehicle',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.19911553844919092},\n",
       " {'description': 'Clarifai image recognition label: vertical',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.284994',\n",
       "   'description': 'Clarifai image recognition label: vertical',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13690,\n",
       "   'modality': None},\n",
       "  'id': 12830,\n",
       "  'max': 0.88984776,\n",
       "  'mean': 0.21959891251449198,\n",
       "  'min': 0.002325927,\n",
       "  'name': 'vertical',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.18227543973226557},\n",
       " {'description': 'Clarifai image recognition label: water',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.295356',\n",
       "   'description': 'Clarifai image recognition label: water',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13691,\n",
       "   'modality': None},\n",
       "  'id': 12831,\n",
       "  'max': 0.9994573,\n",
       "  'mean': 0.815709375258073,\n",
       "  'min': 0.019322928,\n",
       "  'name': 'water',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.24786130045956162},\n",
       " {'description': 'Number of detected faces in scene',\n",
       "  'extracted_feature': {'created_at': '2018-05-10 18:57:05.835125',\n",
       "   'description': 'Number of detected faces in scene',\n",
       "   'extractor_name': 'GoogleVisionAPIFaceExtractor',\n",
       "   'id': 78098,\n",
       "   'modality': None},\n",
       "  'id': 12856,\n",
       "  'max': 1.0,\n",
       "  'mean': 1.0,\n",
       "  'min': 1.0,\n",
       "  'name': 'num_faces',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.0},\n",
       " {'description': 'Face detection confidence',\n",
       "  'extracted_feature': {'created_at': '2018-05-10 03:41:52.456156',\n",
       "   'description': 'Face detection confidence',\n",
       "   'extractor_name': 'GoogleVisionAPIFaceExtractor',\n",
       "   'id': 45901,\n",
       "   'modality': None},\n",
       "  'id': 12850,\n",
       "  'max': 0.569247,\n",
       "  'mean': 0.5383857166666667,\n",
       "  'min': 0.50985885,\n",
       "  'name': 'face_detectionConfidence',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.024517252747322672},\n",
       " {'description': 'Face landmarking confidence',\n",
       "  'extracted_feature': {'created_at': '2018-05-10 03:41:52.468796',\n",
       "   'description': 'Face landmarking confidence',\n",
       "   'extractor_name': 'GoogleVisionAPIFaceExtractor',\n",
       "   'id': 45902,\n",
       "   'modality': None},\n",
       "  'id': 12851,\n",
       "  'max': 0.2362349,\n",
       "  'mean': 0.17620404666666667,\n",
       "  'min': 0.12660252,\n",
       "  'name': 'face_landmarkingConfidence',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.04576393765680514},\n",
       " {'description': 'Clarifai image recognition label: wear',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.306179',\n",
       "   'description': 'Clarifai image recognition label: wear',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13692,\n",
       "   'modality': None},\n",
       "  'id': 12832,\n",
       "  'max': 0.9585774,\n",
       "  'mean': 0.13321366691354686,\n",
       "  'min': 0.0013235305,\n",
       "  'name': 'wear',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.16539076053114915},\n",
       " {'description': 'Clarifai image recognition label: wild',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.316358',\n",
       "   'description': 'Clarifai image recognition label: wild',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13693,\n",
       "   'modality': None},\n",
       "  'id': 12833,\n",
       "  'max': 0.99049455,\n",
       "  'mean': 0.6008990264351011,\n",
       "  'min': 0.0027107615,\n",
       "  'name': 'wild',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2764653804533546},\n",
       " {'description': 'Clarifai image recognition label: wildlife',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.326160',\n",
       "   'description': 'Clarifai image recognition label: wildlife',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13694,\n",
       "   'modality': None},\n",
       "  'id': 12834,\n",
       "  'max': 0.9996503,\n",
       "  'mean': 0.7573567949060384,\n",
       "  'min': 0.004059539,\n",
       "  'name': 'wildlife',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2947684171211708},\n",
       " {'description': 'Clarifai image recognition label: woman',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.335437',\n",
       "   'description': 'Clarifai image recognition label: woman',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13695,\n",
       "   'modality': None},\n",
       "  'id': 12835,\n",
       "  'max': 0.97201276,\n",
       "  'mean': 0.10413855488451824,\n",
       "  'min': 0.00015515627,\n",
       "  'name': 'woman',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.15930563666528505},\n",
       " {'description': 'Clarifai image recognition label: summer',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.214859',\n",
       "   'description': 'Clarifai image recognition label: summer',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13683,\n",
       "   'modality': None},\n",
       "  'id': 12823,\n",
       "  'max': 0.98228455,\n",
       "  'mean': 0.6093765434849042,\n",
       "  'min': 0.020653857,\n",
       "  'name': 'summer',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.21643811818167438},\n",
       " {'description': 'Clarifai image recognition label: sunset',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.223931',\n",
       "   'description': 'Clarifai image recognition label: sunset',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13684,\n",
       "   'modality': None},\n",
       "  'id': 12824,\n",
       "  'max': 0.9977242,\n",
       "  'mean': 0.2932213824423996,\n",
       "  'min': 0.0010584235,\n",
       "  'name': 'sunset',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.27073014232792386},\n",
       " {'description': 'Clarifai image recognition label: technology',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.233042',\n",
       "   'description': 'Clarifai image recognition label: technology',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13685,\n",
       "   'modality': None},\n",
       "  'id': 12825,\n",
       "  'max': 0.9529203,\n",
       "  'mean': 0.040695632881485956,\n",
       "  'min': 0.00047125906,\n",
       "  'name': 'technology',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.08240536392601498},\n",
       " {'description': 'Clarifai image recognition label: wood',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.344855',\n",
       "   'description': 'Clarifai image recognition label: wood',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13696,\n",
       "   'modality': None},\n",
       "  'id': 12836,\n",
       "  'max': 0.9977058,\n",
       "  'mean': 0.48839724101659227,\n",
       "  'min': 0.004465725,\n",
       "  'name': 'wood',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.3168350887837835},\n",
       " {'description': 'Clarifai image recognition label: writing',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.354198',\n",
       "   'description': 'Clarifai image recognition label: writing',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13697,\n",
       "   'modality': None},\n",
       "  'id': 12837,\n",
       "  'max': 0.57347864,\n",
       "  'mean': 0.011625489801136256,\n",
       "  'min': 4.2955908e-05,\n",
       "  'name': 'writing',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.029336758407278077},\n",
       " {'description': 'Average luminosity of the pixels',\n",
       "  'extracted_feature': {'created_at': '2018-05-10 03:38:26.640070',\n",
       "   'description': 'Average luminosity of the pixels',\n",
       "   'extractor_name': 'BrightnessExtractor',\n",
       "   'id': 45898,\n",
       "   'modality': None},\n",
       "  'id': 12847,\n",
       "  'max': 0.772205239348826,\n",
       "  'mean': 0.40374342746977926,\n",
       "  'min': 0.03672315268700073,\n",
       "  'name': 'brightness',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.11977787247576753},\n",
       " {'description': 'Variance of color channels',\n",
       "  'extracted_feature': {'created_at': '2018-05-10 03:39:32.416049',\n",
       "   'description': 'Variance of color channels',\n",
       "   'extractor_name': 'VibranceExtractor',\n",
       "   'id': 45899,\n",
       "   'modality': None},\n",
       "  'id': 12848,\n",
       "  'max': 3301.034799811386,\n",
       "  'mean': 216.0450773584538,\n",
       "  'min': 1.963405349794239,\n",
       "  'name': 'vibrance',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 272.9218895241515},\n",
       " {'description': 'Degree of blur/sharpness of the image',\n",
       "  'extracted_feature': {'created_at': '2018-05-10 03:40:37.793193',\n",
       "   'description': 'Degree of blur/sharpness of the image',\n",
       "   'extractor_name': 'SharpnessExtractor',\n",
       "   'id': 45900,\n",
       "   'modality': None},\n",
       "  'id': 12849,\n",
       "  'max': 1.0,\n",
       "  'mean': 0.4624897688138001,\n",
       "  'min': 0.050980392156862744,\n",
       "  'name': 'sharpness',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.22334961536977535},\n",
       " {'description': 'Root mean square (RMS) energy from audio',\n",
       "  'extracted_feature': {'created_at': '2018-05-22 23:07:17.520545',\n",
       "   'description': 'Root mean square (RMS) energy from audio',\n",
       "   'extractor_name': 'RMSEExtractor',\n",
       "   'id': 84252,\n",
       "   'modality': None},\n",
       "  'id': 12904,\n",
       "  'max': 0.040239984535671555,\n",
       "  'mean': 0.01370024898521164,\n",
       "  'min': 0.0010826961847404289,\n",
       "  'name': 'rmse',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.00538244314283984},\n",
       " {'description': 'Speech (binarized, on or off)',\n",
       "  'extracted_feature': {'created_at': '2018-05-23 01:40:47.717434',\n",
       "   'description': 'Speech (binarized, on or off)',\n",
       "   'extractor_name': 'ComplexTextExtractor',\n",
       "   'id': 84257,\n",
       "   'modality': None},\n",
       "  'id': 12905,\n",
       "  'max': 1.0,\n",
       "  'mean': 1.0,\n",
       "  'min': 1.0,\n",
       "  'name': 'speech',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.0},\n",
       " {'description': 'Transitions between scene cuts in video',\n",
       "  'extracted_feature': {'created_at': '2018-05-24 20:47:16.560766',\n",
       "   'description': 'Transitions between scene cuts in video',\n",
       "   'extractor_name': 'GoogleVideoAPIShotDetectionExtractor',\n",
       "   'id': 84269,\n",
       "   'modality': None},\n",
       "  'id': 12913,\n",
       "  'max': 1.0,\n",
       "  'mean': 1.0,\n",
       "  'min': 1.0,\n",
       "  'name': 'shot_change',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.0},\n",
       " {'description': 'Clarifai image recognition label: illustration',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.004276',\n",
       "   'description': 'Clarifai image recognition label: illustration',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13661,\n",
       "   'modality': None},\n",
       "  'id': 12801,\n",
       "  'max': 0.97412825,\n",
       "  'mean': 0.11408826157608296,\n",
       "  'min': 0.0009184544,\n",
       "  'name': 'illustration',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.17205696457048703},\n",
       " {'description': 'Clarifai image recognition label: image',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.013714',\n",
       "   'description': 'Clarifai image recognition label: image',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13662,\n",
       "   'modality': None},\n",
       "  'id': 12802,\n",
       "  'max': 0.9553325,\n",
       "  'mean': 0.3793037038973484,\n",
       "  'min': 0.028450325,\n",
       "  'name': 'image',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.19875368221493192},\n",
       " {'description': 'Clarifai image recognition label: indoors',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.022910',\n",
       "   'description': 'Clarifai image recognition label: indoors',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13663,\n",
       "   'modality': None},\n",
       "  'id': 12803,\n",
       "  'max': 0.8663614,\n",
       "  'mean': 0.10621965877306905,\n",
       "  'min': 0.0004937579,\n",
       "  'name': 'indoors',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.15964261883360562},\n",
       " {'description': 'Clarifai image recognition label: landscape',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.032165',\n",
       "   'description': 'Clarifai image recognition label: landscape',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13664,\n",
       "   'modality': None},\n",
       "  'id': 12804,\n",
       "  'max': 0.9973083,\n",
       "  'mean': 0.6104975364258336,\n",
       "  'min': 0.017336443,\n",
       "  'name': 'landscape',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2901819874142703},\n",
       " {'description': 'Clarifai image recognition label: light',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.041407',\n",
       "   'description': 'Clarifai image recognition label: light',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13665,\n",
       "   'modality': None},\n",
       "  'id': 12805,\n",
       "  'max': 0.99313396,\n",
       "  'mean': 0.5506072866778682,\n",
       "  'min': 0.012241389,\n",
       "  'name': 'light',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.23407387536373445},\n",
       " {'description': 'Clarifai image recognition label: man',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.050676',\n",
       "   'description': 'Clarifai image recognition label: man',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13666,\n",
       "   'modality': None},\n",
       "  'id': 12806,\n",
       "  'max': 0.9734366,\n",
       "  'mean': 0.13857123038745078,\n",
       "  'min': 0.0013642041,\n",
       "  'name': 'man',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.17358403156064986},\n",
       " {'description': 'Clarifai image recognition label: military',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.060071',\n",
       "   'description': 'Clarifai image recognition label: military',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13667,\n",
       "   'modality': None},\n",
       "  'id': 12807,\n",
       "  'max': 0.8863429,\n",
       "  'mean': 0.06101133165750065,\n",
       "  'min': 0.00022471565,\n",
       "  'name': 'military',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.08273193893158447},\n",
       " {'description': 'Clarifai image recognition label: abstract',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.712347',\n",
       "   'description': 'Clarifai image recognition label: abstract',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13631,\n",
       "   'modality': None},\n",
       "  'id': 12771,\n",
       "  'max': 0.9992758,\n",
       "  'mean': 0.27167737192482544,\n",
       "  'min': 0.00028673618,\n",
       "  'name': 'abstract',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.31140956651031376},\n",
       " {'description': 'Clarifai image recognition label: car',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.816355',\n",
       "   'description': 'Clarifai image recognition label: car',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13641,\n",
       "   'modality': None},\n",
       "  'id': 12781,\n",
       "  'max': 0.937876,\n",
       "  'mean': 0.024091226818083487,\n",
       "  'min': 0.00028337908,\n",
       "  'name': 'car',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.04004265757550984},\n",
       " {'description': 'Clarifai image recognition label: child',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.825999',\n",
       "   'description': 'Clarifai image recognition label: child',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13642,\n",
       "   'modality': None},\n",
       "  'id': 12782,\n",
       "  'max': 0.8939856,\n",
       "  'mean': 0.09754650243464164,\n",
       "  'min': 0.00055619737,\n",
       "  'name': 'child',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.12502912468965852},\n",
       " {'description': 'Clarifai image recognition label: city',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.835148',\n",
       "   'description': 'Clarifai image recognition label: city',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13643,\n",
       "   'modality': None},\n",
       "  'id': 12783,\n",
       "  'max': 0.9172338,\n",
       "  'mean': 0.10251257603398267,\n",
       "  'min': 0.0007789538,\n",
       "  'name': 'city',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.11986290410978644},\n",
       " {'description': 'Clarifai image recognition label: color',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.844397',\n",
       "   'description': 'Clarifai image recognition label: color',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13644,\n",
       "   'modality': None},\n",
       "  'id': 12784,\n",
       "  'max': 0.9894476,\n",
       "  'mean': 0.6098612847442898,\n",
       "  'min': 0.04129202,\n",
       "  'name': 'color',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.22961504702023444},\n",
       " {'description': 'Clarifai image recognition label: competition',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.854132',\n",
       "   'description': 'Clarifai image recognition label: competition',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13645,\n",
       "   'modality': None},\n",
       "  'id': 12785,\n",
       "  'max': 0.96362174,\n",
       "  'mean': 0.15535570039697558,\n",
       "  'min': 0.00044883357,\n",
       "  'name': 'competition',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.16795027130298357},\n",
       " {'description': 'Clarifai image recognition label: creativity',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.863414',\n",
       "   'description': 'Clarifai image recognition label: creativity',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13646,\n",
       "   'modality': None},\n",
       "  'id': 12786,\n",
       "  'max': 0.87069327,\n",
       "  'mean': 0.05333248678904699,\n",
       "  'min': 9.545405e-05,\n",
       "  'name': 'creativity',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.09880264217786493},\n",
       " {'description': 'Clarifai image recognition label: dark',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.872489',\n",
       "   'description': 'Clarifai image recognition label: dark',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13647,\n",
       "   'modality': None},\n",
       "  'id': 12787,\n",
       "  'max': 0.9882182,\n",
       "  'mean': 0.3242534958889997,\n",
       "  'min': 0.0058510695,\n",
       "  'name': 'dark',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.25294245066492155},\n",
       " {'description': 'Clarifai image recognition label: daylight',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.881578',\n",
       "   'description': 'Clarifai image recognition label: daylight',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13648,\n",
       "   'modality': None},\n",
       "  'id': 12788,\n",
       "  'max': 0.98870385,\n",
       "  'mean': 0.8017381956495143,\n",
       "  'min': 0.021070436,\n",
       "  'name': 'daylight',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.14537676107116657},\n",
       " {'description': 'Clarifai image recognition label: design',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.891501',\n",
       "   'description': 'Clarifai image recognition label: design',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13649,\n",
       "   'modality': None},\n",
       "  'id': 12789,\n",
       "  'max': 0.9919585,\n",
       "  'mean': 0.16086629338317932,\n",
       "  'min': 0.00071848603,\n",
       "  'name': 'design',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.20511705665925042},\n",
       " {'description': 'Clarifai image recognition label: home',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.985678',\n",
       "   'description': 'Clarifai image recognition label: home',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13659,\n",
       "   'modality': None},\n",
       "  'id': 12799,\n",
       "  'max': 0.6331376,\n",
       "  'mean': 0.04123992552719874,\n",
       "  'min': 0.00023987997,\n",
       "  'name': 'home',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.058369132856348344},\n",
       " {'description': 'Clarifai image recognition label: alphabet',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.747836',\n",
       "   'description': 'Clarifai image recognition label: alphabet',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13634,\n",
       "   'modality': None},\n",
       "  'id': 12774,\n",
       "  'max': 0.67851746,\n",
       "  'mean': 0.0024747603981010763,\n",
       "  'min': 2.4722492e-06,\n",
       "  'name': 'alphabet',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.024941578193331},\n",
       " {'description': 'Clarifai image recognition label: animal',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.757058',\n",
       "   'description': 'Clarifai image recognition label: animal',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13635,\n",
       "   'modality': None},\n",
       "  'id': 12775,\n",
       "  'max': 0.99643934,\n",
       "  'mean': 0.602321535607695,\n",
       "  'min': 0.0007523959,\n",
       "  'name': 'animal',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.3382203258570807},\n",
       " {'description': 'Clarifai image recognition label: architecture',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.768089',\n",
       "   'description': 'Clarifai image recognition label: architecture',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13636,\n",
       "   'modality': None},\n",
       "  'id': 12776,\n",
       "  'max': 0.8600687,\n",
       "  'mean': 0.07857983580971908,\n",
       "  'min': 0.0007736794,\n",
       "  'name': 'architecture',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.10991895301434651},\n",
       " {'description': 'Clarifai image recognition label: art',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.777851',\n",
       "   'description': 'Clarifai image recognition label: art',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13637,\n",
       "   'modality': None},\n",
       "  'id': 12777,\n",
       "  'max': 0.9852028,\n",
       "  'mean': 0.2589916975022053,\n",
       "  'min': 0.0047565056,\n",
       "  'name': 'art',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.24853632525645372},\n",
       " {'description': 'Clarifai image recognition label: blur',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.788011',\n",
       "   'description': 'Clarifai image recognition label: blur',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13638,\n",
       "   'modality': None},\n",
       "  'id': 12778,\n",
       "  'max': 0.9994553,\n",
       "  'mean': 0.4814303087637175,\n",
       "  'min': 0.005206556,\n",
       "  'name': 'blur',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2989371827410122},\n",
       " {'description': 'Clarifai image recognition label: building',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.797085',\n",
       "   'description': 'Clarifai image recognition label: building',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13639,\n",
       "   'modality': None},\n",
       "  'id': 12779,\n",
       "  'max': 0.7902745,\n",
       "  'mean': 0.06984230066356,\n",
       "  'min': 0.00065433455,\n",
       "  'name': 'building',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.09689561507311552},\n",
       " {'description': 'Clarifai image recognition label: business',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:17.806711',\n",
       "   'description': 'Clarifai image recognition label: business',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13640,\n",
       "   'modality': None},\n",
       "  'id': 12780,\n",
       "  'max': 0.94202685,\n",
       "  'mean': 0.0386192366534681,\n",
       "  'min': 8.744527e-05,\n",
       "  'name': 'business',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.07024180207951826},\n",
       " {'description': 'Clarifai image recognition label: music',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.070019',\n",
       "   'description': 'Clarifai image recognition label: music',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13668,\n",
       "   'modality': None},\n",
       "  'id': 12808,\n",
       "  'max': 0.73752075,\n",
       "  'mean': 0.03698833332820031,\n",
       "  'min': 6.761988e-05,\n",
       "  'name': 'music',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.07235082756616158},\n",
       " {'description': 'Clarifai image recognition label: nature',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.080429',\n",
       "   'description': 'Clarifai image recognition label: nature',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13669,\n",
       "   'modality': None},\n",
       "  'id': 12809,\n",
       "  'max': 0.9977137,\n",
       "  'mean': 0.9410946966106589,\n",
       "  'min': 0.13726653,\n",
       "  'name': 'nature',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.06511010069300058},\n",
       " {'description': 'Clarifai image recognition label: old',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.090295',\n",
       "   'description': 'Clarifai image recognition label: old',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13670,\n",
       "   'modality': None},\n",
       "  'id': 12810,\n",
       "  'max': 0.9839686,\n",
       "  'mean': 0.1506207555259123,\n",
       "  'min': 0.0008815618,\n",
       "  'name': 'old',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.18516621586384271},\n",
       " {'description': 'Clarifai image recognition label: one',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.099467',\n",
       "   'description': 'Clarifai image recognition label: one',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13671,\n",
       "   'modality': None},\n",
       "  'id': 12811,\n",
       "  'max': 0.9947323,\n",
       "  'mean': 0.6292880574544499,\n",
       "  'min': 0.009978576,\n",
       "  'name': 'one',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2851394636983383},\n",
       " {'description': 'Clarifai image recognition label: outdoors',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.108684',\n",
       "   'description': 'Clarifai image recognition label: outdoors',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13672,\n",
       "   'modality': None},\n",
       "  'id': 12812,\n",
       "  'max': 0.9912671,\n",
       "  'mean': 0.926054286207666,\n",
       "  'min': 0.105585515,\n",
       "  'name': 'outdoors',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.0829076823315818},\n",
       " {'description': 'Clarifai image recognition label: pattern',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.118021',\n",
       "   'description': 'Clarifai image recognition label: pattern',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13673,\n",
       "   'modality': None},\n",
       "  'id': 12813,\n",
       "  'max': 0.9936938,\n",
       "  'mean': 0.3418008628033342,\n",
       "  'min': 0.0035169567,\n",
       "  'name': 'pattern',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.25907062664988917},\n",
       " {'description': 'Clarifai image recognition label: people',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.127237',\n",
       "   'description': 'Clarifai image recognition label: people',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13674,\n",
       "   'modality': None},\n",
       "  'id': 12814,\n",
       "  'max': 0.99549085,\n",
       "  'mean': 0.32556630841037015,\n",
       "  'min': 0.0021657457,\n",
       "  'name': 'people',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.27661466291687437},\n",
       " {'description': 'Clarifai image recognition label: portrait',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.137113',\n",
       "   'description': 'Clarifai image recognition label: portrait',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13675,\n",
       "   'modality': None},\n",
       "  'id': 12815,\n",
       "  'max': 0.9909054,\n",
       "  'mean': 0.3949221562683119,\n",
       "  'min': 0.0011023709,\n",
       "  'name': 'portrait',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.31162038631026867},\n",
       " {'description': 'Clarifai image recognition label: recreation',\n",
       "  'extracted_feature': {'created_at': '2018-05-09 22:42:18.146806',\n",
       "   'description': 'Clarifai image recognition label: recreation',\n",
       "   'extractor_name': 'ClarifaiAPIImageExtractor',\n",
       "   'id': 13676,\n",
       "   'modality': None},\n",
       "  'id': 12816,\n",
       "  'max': 0.96892655,\n",
       "  'mean': 0.3686949568861118,\n",
       "  'min': 0.0007801657,\n",
       "  'name': 'recreation',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 0.2556060697265688},\n",
       " {'description': 'Global signal within whole-brain mask',\n",
       "  'id': 12731,\n",
       "  'max': 1372.79833984375,\n",
       "  'mean': 1118.4517260715497,\n",
       "  'min': 711.5427856445312,\n",
       "  'name': 'GlobalSignal',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 134.66321322658996},\n",
       " {'description': 'Average signal in White Matter mask',\n",
       "  'id': 12730,\n",
       "  'max': 1491.898193359375,\n",
       "  'mean': 1215.3048626203492,\n",
       "  'min': 807.2579345703125,\n",
       "  'name': 'WhiteMatter',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 146.67133084891196},\n",
       " {'description': 'Derivative of RMS variance over voxels, non-standardized',\n",
       "  'id': 12733,\n",
       "  'max': 134.82197571,\n",
       "  'mean': 26.23222829489447,\n",
       "  'min': 13.86929417,\n",
       "  'name': 'non-stdDVARS',\n",
       "  'num_na': 114,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 5.790487646179467},\n",
       " {'description': 'Derivative of RMS variance over voxels, voxel-wise standardized',\n",
       "  'id': 12734,\n",
       "  'max': 6.11489916,\n",
       "  'mean': 0.9743249312677739,\n",
       "  'min': 0.59328508,\n",
       "  'name': 'vx-wisestdDVARS',\n",
       "  'num_na': 114,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.14522608738864773},\n",
       " {'description': 'Esimated bulk-head motion',\n",
       "  'id': 12735,\n",
       "  'max': 4.47971425,\n",
       "  'mean': 0.14797270672135424,\n",
       "  'min': 0.001972937,\n",
       "  'name': 'FramewiseDisplacement',\n",
       "  'num_na': 76,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.14117185482380565},\n",
       " {'description': 'Non-steady state volume detection',\n",
       "  'id': 12767,\n",
       "  'max': 1.0,\n",
       "  'mean': 0.0027662517289073307,\n",
       "  'min': 0.0,\n",
       "  'name': 'NonSteadyStateOutlier00',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.05252963820088644},\n",
       " {'description': 'Non-steady state volume detection',\n",
       "  'id': 12770,\n",
       "  'max': 1.0,\n",
       "  'mean': 0.0028268551236749115,\n",
       "  'min': 0.0,\n",
       "  'name': 'NonSteadyStateOutlier01',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.053111745901364985},\n",
       " {'description': 'Rigid-body transform parameter (rotation)',\n",
       "  'id': 12764,\n",
       "  'max': 0.0247134,\n",
       "  'mean': 0.002668656542090645,\n",
       "  'min': 0.0,\n",
       "  'name': 'RotY',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.0031529968351300284},\n",
       " {'description': 'Rigid-body transform parameter (rotation)',\n",
       "  'id': 12765,\n",
       "  'max': 0.024347099999999997,\n",
       "  'mean': 0.0020331771134050694,\n",
       "  'min': 0.0,\n",
       "  'name': 'RotZ',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.002747952165998967},\n",
       " {'description': 'Rigid-body transform parameter (translation)',\n",
       "  'id': 12760,\n",
       "  'max': 0.976377,\n",
       "  'mean': 0.09675888198348459,\n",
       "  'min': 0.0,\n",
       "  'name': 'X',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.10531202124977529},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 12748,\n",
       "  'max': 0.0769222462,\n",
       "  'mean': 0.046389847267209745,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine00',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.022559832195388856},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 12749,\n",
       "  'max': 0.0769197542,\n",
       "  'mean': 0.04641541928199355,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine01',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.022540282222491156},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 12750,\n",
       "  'max': 0.0769222462,\n",
       "  'mean': 0.04643314786677258,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine02',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.022525839201314173},\n",
       " {'description': 'Rigid-body transform parameter (translation)',\n",
       "  'id': 12761,\n",
       "  'max': 1.20694,\n",
       "  'mean': 0.1022900450737417,\n",
       "  'min': 0.0,\n",
       "  'name': 'Y',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.11513365774908595},\n",
       " {'description': 'Rigid-body transform parameter (translation)',\n",
       "  'id': 12762,\n",
       "  'max': 3.47155,\n",
       "  'mean': 0.3271453201714803,\n",
       "  'min': 0.0,\n",
       "  'name': 'Z',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.5033065580503807},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 12756,\n",
       "  'max': 0.0769222462,\n",
       "  'mean': 0.046396292720926324,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine08',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.02255483735734539},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 12757,\n",
       "  'max': 0.0769197542,\n",
       "  'mean': 0.04641984911423366,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine09',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.02253668658369096},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 12758,\n",
       "  'max': 0.0769222462,\n",
       "  'mean': 0.04644344299270493,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine10',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.022512899505996557},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 12759,\n",
       "  'max': 0.0769097864,\n",
       "  'mean': 0.04644580274364571,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine11',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.0225163428856486},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 12766,\n",
       "  'max': 0.0739214463,\n",
       "  'mean': 0.04586079440076712,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine12',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.022041688833862916},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 12768,\n",
       "  'max': 0.0696712759,\n",
       "  'mean': 0.04435583113398058,\n",
       "  'min': 0.0005312694,\n",
       "  'name': 'Cosine13',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.021443586069048184},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 12769,\n",
       "  'max': 0.069672795,\n",
       "  'mean': 0.04435550875339806,\n",
       "  'min': 0.0002656367,\n",
       "  'name': 'Cosine14',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.021444253012163184},\n",
       " {'description': 'Derivative of RMS variance over voxels, standardized',\n",
       "  'id': 12732,\n",
       "  'max': 6.46463108,\n",
       "  'mean': 1.3203675351195858,\n",
       "  'min': 0.63518429,\n",
       "  'name': 'stdDVARS',\n",
       "  'num_na': 114,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.2517655166308492},\n",
       " {'description': 'Rigid-body transform parameter (rotation)',\n",
       "  'id': 12763,\n",
       "  'max': 0.0517616,\n",
       "  'mean': 0.005618808962484865,\n",
       "  'min': 0.0,\n",
       "  'name': 'RotX',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.007469553298415384},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 12736,\n",
       "  'max': 0.228829187,\n",
       "  'mean': 0.04312913647210696,\n",
       "  'min': 0.0,\n",
       "  'name': 'tCompCor00',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.02829748974407296},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 12737,\n",
       "  'max': 0.2252357086,\n",
       "  'mean': 0.04261872418853474,\n",
       "  'min': 0.0,\n",
       "  'name': 'tCompCor01',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.02779156009319651},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 12738,\n",
       "  'max': 0.2343765628,\n",
       "  'mean': 0.04128390373531358,\n",
       "  'min': 0.0,\n",
       "  'name': 'tCompCor02',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.030588497122984535},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 12739,\n",
       "  'max': 0.2611415934,\n",
       "  'mean': 0.04115109582590511,\n",
       "  'min': 0.0,\n",
       "  'name': 'tCompCor03',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.03113168953823332},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 12740,\n",
       "  'max': 0.5060172628,\n",
       "  'mean': 0.04037476225622376,\n",
       "  'min': 0.0,\n",
       "  'name': 'tCompCor04',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.031936196432208824},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 12741,\n",
       "  'max': 0.2572493529,\n",
       "  'mean': 0.04088469516924154,\n",
       "  'min': 0.0,\n",
       "  'name': 'tCompCor05',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.031064170607208577},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 12742,\n",
       "  'max': 0.9415761996,\n",
       "  'mean': 0.04178570028166265,\n",
       "  'min': 0.0,\n",
       "  'name': 'aCompCor00',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.031629600144929756},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 12743,\n",
       "  'max': 0.4541642219,\n",
       "  'mean': 0.04218918816882778,\n",
       "  'min': 0.0,\n",
       "  'name': 'aCompCor01',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.02967102935537023},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 12744,\n",
       "  'max': 0.3472921339,\n",
       "  'mean': 0.04143504796225197,\n",
       "  'min': 0.0,\n",
       "  'name': 'aCompCor02',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.03066102322661918},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 12745,\n",
       "  'max': 0.5769386392,\n",
       "  'mean': 0.040983585752116886,\n",
       "  'min': 0.0,\n",
       "  'name': 'aCompCor03',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.031684216501049946},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 12746,\n",
       "  'max': 0.4075255747,\n",
       "  'mean': 0.04057288175714419,\n",
       "  'min': 0.0,\n",
       "  'name': 'aCompCor04',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.03163489993028379},\n",
       " {'description': 'Noise components estimated using component based noise correction method',\n",
       "  'id': 12747,\n",
       "  'max': 0.3632925835,\n",
       "  'mean': 0.04053186078084648,\n",
       "  'min': 0.0,\n",
       "  'name': 'aCompCor05',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.03176032321517707},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 12751,\n",
       "  'max': 0.0769097864,\n",
       "  'mean': 0.04638069719654142,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine03',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.022567636183533225},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 12752,\n",
       "  'max': 0.0769222462,\n",
       "  'mean': 0.046389660672008774,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine04',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.022560215905509114},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 12753,\n",
       "  'max': 0.0769197542,\n",
       "  'mean': 0.04641103570359161,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine05',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.022543789528845164},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 12754,\n",
       "  'max': 0.0769222462,\n",
       "  'mean': 0.04643971017435742,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine06',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.022520598932243917},\n",
       " {'description': 'Cosine basis set for high-pass filtering',\n",
       "  'id': 12755,\n",
       "  'max': 0.0769230769,\n",
       "  'mean': 0.04625770252099898,\n",
       "  'min': 0.0,\n",
       "  'name': 'Cosine07',\n",
       "  'num_na': 0,\n",
       "  'source': 'fmriprep',\n",
       "  'stddev': 0.022663407924203974},\n",
       " {'description': 'RGB Channel',\n",
       "  'extracted_feature': {'created_at': '2018-05-10 18:58:10.076277',\n",
       "   'description': 'RGB Channel',\n",
       "   'extractor_name': 'GoogleVisionAPIPropertyExtractor',\n",
       "   'id': 78099,\n",
       "   'modality': None},\n",
       "  'id': 12857,\n",
       "  'max': 9.0,\n",
       "  'mean': 3.897348385402993,\n",
       "  'min': 1.0,\n",
       "  'name': 'num_colors_0_07',\n",
       "  'num_na': 0,\n",
       "  'source': 'extracted',\n",
       "  'stddev': 1.2906504768987015}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.predictors.get(run_id=dataset['runs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bunch of useful information to help me choose some features! Let's keep it simple and go with 'rmse' (sound volume) and 'FramewiseDisplacement':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build an analysis. For this, we can use the `Analysis` class, which makes it easy to build an Analysis locally, by mirroring the Analysis representation on the server. \n",
    "\n",
    "To build an `Analysis` object, we can use the `create_analysis` which pre-populates our `Analysis` object with the relevant information, including a pre-build BIDS model, and registers it to the API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = api.analyses.create_analysis(\n",
    "    dataset_name='Life', name='My new analysis!',\n",
    "    predictor_names=['rmse', 'FramewiseDisplacement'],\n",
    "    hrf_variables=['rmse'], \n",
    "    subject=['rid000001', 'rid000005']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This newly created analysis has been assigned a unique ID by the Neuroscout API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9B8pA'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.hash_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-01-24T21:5'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some properties are read-only and came from the server\n",
    "analysis.created_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis creation function has found the runs relevant to the subjects we're interested in, and created a basic BIDS-Model for our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Input': {'Subject': ['rid000001', 'rid000005'], 'Task': 'life'},\n",
       " 'Name': 'My new analysis!',\n",
       " 'Steps': [{'AutoContrasts': True,\n",
       "   'Contrasts': [],\n",
       "   'Level': 'Run',\n",
       "   'Model': {'X': ['rmse', 'FramewiseDisplacement']},\n",
       "   'Transformations': [{'Input': ['rmse'], 'Name': 'Convolve'}]},\n",
       "  {'AutoContrasts': True, 'Level': 'Subject'},\n",
       "  {'AutoContrasts': True, 'Level': 'Dataset'}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[235, 236, 237, 238, 239, 240, 241, 242]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12735, 12904]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neuroscout API Predictor IDs\n",
    "analysis.predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can edit this Analysis object to fill in any other Analysis details, and push them to the Neuroscout API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.description = \"This is my analysis, and it's probably the best\"\n",
    "analysis.push()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reports\n",
    "\n",
    "Now that we have created and design an analysis we can generate some reports based on our design\n",
    "\n",
    "Let's generate a report using only a single run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generated_at': '2019-01-24T21:5',\n",
       " 'result': None,\n",
       " 'status': 'PENDING',\n",
       " 'traceback': None}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.generate_report(run_id=analysis.runs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report should take a few seconds to a few minutes to compile, and we can check its status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = analysis.get_report(run_id=analysis.runs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generated_at': '2019-01-24T21:5',\n",
       " 'result': {'contrast_plot': ['alpha.neuroscout.org/reports/9B8pA/sub-rid000001_task-life_run-2_contrast_matrix.png'],\n",
       "  'design_matrix': ['alpha.neuroscout.org/reports/9B8pA/sub-rid000001_task-life_run-2_design_matrix.tsv'],\n",
       "  'design_matrix_corrplot': ['alpha.neuroscout.org/reports/9B8pA/sub-rid000001_task-life_run-2_design_matrix_corrplot.png'],\n",
       "  'design_matrix_plot': ['alpha.neuroscout.org/reports/9B8pA/sub-rid000001_task-life_run-2_design_matrix_plot.png']},\n",
       " 'status': 'OK',\n",
       " 'traceback': None}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generated_at': '2019-01-24T21:5',\n",
       " 'result': {'contrast_plot': ['alpha.neuroscout.org/reports/9B8pA/sub-rid000001_task-life_run-2_contrast_matrix.png'],\n",
       "  'design_matrix': ['alpha.neuroscout.org/reports/9B8pA/sub-rid000001_task-life_run-2_design_matrix.tsv'],\n",
       "  'design_matrix_corrplot': ['alpha.neuroscout.org/reports/9B8pA/sub-rid000001_task-life_run-2_design_matrix_corrplot.png'],\n",
       "  'design_matrix_plot': ['alpha.neuroscout.org/reports/9B8pA/sub-rid000001_task-life_run-2_design_matrix_plot.png']},\n",
       " 'status': 'OK',\n",
       " 'traceback': None}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, our report was sucesfully generated with no errors. Now lets take a look at the resulting design matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://alpha.neuroscout.org/reports/9B8pA/sub-rid000001_task-life_run-2_design_matrix_plot.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"https://\" + report['result']['design_matrix_plot'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the analysis\n",
    "Finally, now that we are happy with our analysis, we can ask Neuroscout to verify the analysis, and generate an analysis bundle for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compile_traceback': '', 'status': 'PENDING'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compile_traceback': '', 'status': 'PASSED'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our analysis passed with no errors. We can now run our analysis using the `neuroscout-cli`. \n",
    "\n",
    "For more information on the `neuroscout-cli`, see here: https://github.com/neuroscout/neuroscout-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloning our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've gone off and run our analysis, we realized we want to make some changes. In this case, I'm just going to change the analysis name.\n",
    "\n",
    "With Neuroscout this is easy, because I simply clone my previous analysis, and take off from I left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MDOOA'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_analysis = analysis.clone()\n",
    "new_analysis.hash_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_analysis.name = 'My new analysis name!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, what if we wanted to take this same model, and apply it to a different model. For example, `dataset_id` 5, which correspond to SherlockMerlin?\n",
    "\n",
    "To do so, we have to use the `fill` function to get the correct `predictors` and `runs`, as these IDS \"correspond to the wrong dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_analysis.predictors = []\n",
    "new_analysis.runs = []\n",
    "new_analysis.dataset_id = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TR': 2.5,\n",
       " 'compile_traceback': '',\n",
       " 'created_at': '2019-01-24T21:5',\n",
       " 'dataset_id': 9,\n",
       " 'description': \"This is my analysis, and it's probably the best\",\n",
       " 'hash_id': 'MDOOA',\n",
       " 'locked': False,\n",
       " 'model': {'Input': {'Subject': ['rid000001', 'rid000005'], 'Task': 'life'},\n",
       "  'Name': 'My new analysis!',\n",
       "  'Steps': [{'AutoContrasts': True,\n",
       "    'Contrasts': [],\n",
       "    'Level': 'Run',\n",
       "    'Model': {'X': ['rmse', 'FramewiseDisplacement']},\n",
       "    'Transformations': [{'Input': ['rmse'], 'Name': 'Convolve'}]},\n",
       "   {'AutoContrasts': True, 'Level': 'Subject'},\n",
       "   {'AutoContrasts': True, 'Level': 'Dataset'}]},\n",
       " 'modified_at': '2019-01-24T21:5',\n",
       " 'name': 'My new analysis!',\n",
       " 'parent_id': '9B8pA',\n",
       " 'predictions': '',\n",
       " 'predictors': [12735, 12904],\n",
       " 'private': True,\n",
       " 'runs': [235, 236, 237, 238, 239, 240, 241, 242],\n",
       " 'status': 'DRAFT',\n",
       " 'submitted_at': '2019-01-24T22:0',\n",
       " 'task_name': 'life'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_analysis.fill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function automatically filled in all available runs for dataset_id = 5, and found the corresponding predictor ids based on the names used in the model. We can now compile this cloned analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compile_traceback': '', 'status': 'PENDING'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_analysis.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compile_traceback': '', 'status': 'PASSED'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_analysis.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, since this analysis also passed, I can easily run this forked version using the `neuroscout-cli`. If you have any questions on how to use the Neuroscout API, please see the API's Swagger Documentation, which covers all possible routes and parameters: https://alpha.neuroscout.org/swagger-ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
